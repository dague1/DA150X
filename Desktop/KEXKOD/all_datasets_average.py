# -*- coding: utf-8 -*-
"""all_datasets_average.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BhfBxOti9tj18C8nlbKoWAZsSF2Cic_w

# BC
"""

#importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns 
import pandas as pd
import math
import time
from sklearn.utils import resample
from imblearn.over_sampling import SMOTE
from statistics import mean
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
from sklearn import svm
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

#Loading datasets
df = pd.read_csv('breast-cancer-wisconsin-modified.csv')
df = df.drop(['id'],axis=1)

labelencoder_y = LabelEncoder()
df['Class'] = labelencoder_y.fit_transform(df['Class'])

df

df.Class.value_counts()

df.isnull().sum()

# X,y,etc should be the size which can be divided by n for n-fold cv. Some lows can be discarded. 
cv = 5
# s will be the size of the dataset <= original dataset size which can be divided by cv. 
s = math.floor(len(df)/cv)*cv
# d is the size of each partitioned dataset
d = int(s/cv)

X = df.iloc[:s,:-1].values
y = df.iloc[:s,-1].values
X_noise = df.iloc[:s,:-1].values.copy()

# 10 datasets which is going to be noised. 10%, 20% and so on. 
noise = []
n_range = range(0,10)
for n in n_range:
    noise.append(df.iloc[:s,:-1].values.copy())

test = df.iloc[:s,8].unique()
print(test)
len(test)



# Make mean, std, max and min of every column
n_range = range(0, X.shape[1])
mean = []
std = []
max = []
min = []

for n in n_range: 
    mean.append(X_noise[:,n].mean())
    std.append(X_noise[:,n].std())
    max.append(X_noise[:,n].max())
    min.append(X_noise[:,n].min())

# New noise 

m_range = range(1,11)
for m in m_range:
    X_noise = noise[m-1]
    
    #noise_levels are going to be 0.1, 0.2,...1(10%,20%...)
    noise_level = 0.1 * m
    
    #How many entries(rows) in the dataset we want to add noise?
    noise_entries_amount = int(X.size * noise_level) 
    
    #Create an array with random int which represent the rows we are going to add noise on(no duplicate rows)
    r = np.random.choice(X.size, noise_entries_amount, replace=False)
    
    r_range = range(0,r.size)
    for n in r_range:
        entry = r[n]
        row = int(entry/X.shape[1])
        column = entry%X.shape[1]
        
        if column == 8:
            while True:
                a = np.random.randint(1, 11)
                if a != 9 and X_noise[row][column] != a:
                    X_noise[row][column] = a
                    break
        else: 
           while True:
                a = np.random.randint(1, 11)
                if X_noise[row][column] != a:
                    X_noise[row][column] = a
                    break 

X

noise[0]

noise[9]

# p stands for partitioned
X_p = []
y_p = []
# Each [] will contain noised dataset 10%, 20%... which are divided in cv(e.g. 5)
noise_p = [[],[],[],[],[],[],[],[],[],[],]

n_range = range(0,10)
for n in n_range:
    for i in range(0, len(X), d):
            noise_p[n].append(noise[n][i:i + d])
for i in range(0, len(X), d):
            X_p.append(X[i:i + d])
            y_p.append(y[i:i + d])

linear_means_ac = []
poly_means_ac = []
rbf_means_ac = []
ann_means_ac = []
rf_means_ac = []

linear_means_f1 = []
poly_means_f1 = []
rbf_means_f1 = []
ann_means_f1 = []
rf_means_f1 = []

linear_means_noise_ac = []
poly_means_noise_ac = []
rbf_means_noise_ac = []
ann_means_noise_ac = []
rf_means_noise_ac = []

linear_means_noise_f1 = []
poly_means_noise_f1 = []
rbf_means_noise_f1 = []
ann_means_noise_f1 = []
rf_means_noise_f1 = []

time_linear_sum_bc = []
time_poly_sum_bc = []
time_rbf_sum_bc = []
time_ann_sum_bc = []
time_rf_sum_bc = []

# Cross Validation noise 0 
from statistics import mean
first = False
scores_linear_ac = []
scores_poly_ac = []
scores_rbf_ac = []
scores_ann_ac = []
scores_rf_ac = []

scores_linear_f1 = []
scores_poly_f1 = []
scores_rbf_f1 = []
scores_ann_f1 = []
scores_rf_f1 = []

time_linear_bc = []
time_poly_bc = []
time_rbf_bc = []
time_ann_bc = []
time_rf_bc = []

for i in range(cv):
    start = time.time()
    X_test = X_p[i]
    y_test = y_p[i]
    first = True
    for k in range(cv):
        if k != i:
            if first != True:
                X_train = np.append(X_train, X_p[k], axis=0)
                y_train = np.append(y_train, y_p[k], axis=0)
            else: 
                X_train = X_p[k]
                y_train = y_p[k]
                first = False

        
    # Now all test, train sets are obtained
    linear = svm.SVC(kernel='linear')
    poly = svm.SVC(kernel='poly')
    rbf = svm.SVC(kernel='rbf')
    ann = MLPClassifier(hidden_layer_sizes=(10,10,10), max_iter=1000)
    rf = RandomForestClassifier(n_estimators=200)
        
    # Our data is biased, we can fix this with SMOTE
    #oversample = SMOTE()
    #X_train, y_train = oversample.fit_resample(X_train, y_train)

    # Train the models
    sc = StandardScaler()
    X_train = sc.fit_transform(X_train)
    X_test = sc.transform(X_test)
    end = time.time()
    t = end-start
    
    linear_start = time.time()
    linear.fit(X_train, y_train)
    pred_linear = linear.predict(X_test)        
    score_linear_ac = accuracy_score(y_test, pred_linear)
    score_linear_f1 = f1_score(y_test, pred_linear)
    scores_linear_ac.append(score_linear_ac)
    scores_linear_f1.append(score_linear_f1)
    linear_end = time.time()
    time_linear_bc.append(t+(linear_end-linear_start))
    
    poly_start = time.time()
    poly.fit(X_train, y_train)
    pred_poly = poly.predict(X_test)        
    score_poly_ac = accuracy_score(y_test, pred_poly)
    score_poly_f1 = f1_score(y_test, pred_poly)
    scores_poly_ac.append(score_poly_ac)
    scores_poly_f1.append(score_poly_f1)
    poly_end = time.time()
    time_poly_bc.append(t+(poly_end-poly_start))
    
    rbf_start = time.time()
    rbf.fit(X_train, y_train)
    pred_rbf = rbf.predict(X_test)
    score_rbf_ac = accuracy_score(y_test, pred_rbf)
    scores_rbf_ac.append(score_rbf_ac)
    score_rbf_f1 = f1_score(y_test, pred_rbf)
    scores_rbf_f1.append(score_rbf_f1)
    rbf_end = time.time()
    time_rbf_bc.append(t+(rbf_end-rbf_start))

    ann_start = time.time()
    ann.fit(X_train, y_train)
    pred_ann = ann.predict(X_test)
    score_ann_ac = accuracy_score(y_test, pred_ann)
    scores_ann_ac.append(score_ann_ac)
    score_ann_f1 = f1_score(y_test, pred_ann)
    scores_ann_f1.append(score_ann_f1)
    ann_end = time.time()
    time_ann_bc.append(t+(ann_end-ann_start))

    rf_start = time.time()
    rf.fit(X_train, y_train)
    pred_rf = rf.predict(X_test)
    score_rf_ac = accuracy_score(y_test, pred_rf)
    scores_rf_ac.append(score_rf_ac)
    score_rf_f1 = f1_score(y_test, pred_rf)
    scores_rf_f1.append(score_rf_f1)
    rf_end = time.time()
    time_rf_bc.append(t+(rf_end-rf_start))

time_linear_sum_bc.append(sum(time_linear_bc))
time_poly_sum_bc.append(sum(time_poly_bc))
time_rbf_sum_bc.append(sum(time_rbf_bc))
time_ann_sum_bc.append(sum(time_ann_bc))
time_rf_sum_bc.append(sum(time_rf_bc))

    
print("Noise level 0")    
print("Linear accuracy mean is: ", mean(scores_linear_ac))
print("Linear f1 mean is: ", mean(scores_linear_f1))
print("")  
linear_means_ac.append(mean(scores_linear_ac))   
linear_means_f1.append(mean(scores_linear_f1))     

print("Noise level 0")    
print("Poly accuracy mean is: ", mean(scores_poly_ac))
print("Poly f1 mean is: ", mean(scores_poly_f1))
print("")  
poly_means_ac.append(mean(scores_poly_ac))   
poly_means_f1.append(mean(scores_poly_f1))     

print("Noise level 0")    
print("Rbf accuracy mean is: ", mean(scores_rbf_ac))
print("Rbf f1 mean is: ", mean(scores_rbf_f1))
print("")
rbf_means_ac.append(mean(scores_rbf_ac))
rbf_means_f1.append(mean(scores_rbf_f1))

print("Noise level 0")    
print("ANN accuracy mean is: ", mean(scores_ann_ac))
print("ANN f1 mean is: ", mean(scores_ann_f1))
print("")
ann_means_ac.append(mean(scores_ann_ac))
ann_means_f1.append(mean(scores_ann_f1))

print("Noise level 0")    
print("RF accuracy mean is: ", mean(scores_rf_ac))
print("RF f1 mean is: ", mean(scores_rf_f1))
print("")
rf_means_ac.append(mean(scores_rf_ac))
rf_means_f1.append(mean(scores_rf_f1))

print("Time linear: ", time_linear_sum_bc[0])
print("Time poly: ", time_poly_sum_bc[0])
print("Time rbf: ", time_rbf_sum_bc[0])
print("Time ann: ", time_ann_sum_bc[0])
print("Time rf: ", time_rf_sum_bc[0])


# Cross Validation Linear
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_linear_ac = []
    scores_linear_f1 = []
  
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
        
                    
        # Now all test, train sets are obtained
        linear = svm.SVC(kernel='linear')
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train)
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        linear.fit(X_train, y_train)
        pred_linear = linear.predict(X_test)        
        score_linear_ac = accuracy_score(y_test, pred_linear)
        score_linear_f1 = f1_score(y_test, pred_linear)

        scores_linear_ac.append(score_linear_ac)
        scores_linear_f1.append(score_linear_f1)
    end = time.time()
    t = end-start
    time_linear_sum_bc.append(t)

    print("Noise level: " + str((n+1)*10) + '%')    
    print("Linear accuracy mean is: ", mean(scores_linear_ac))
    print("Linear f1 mean is: ", mean(scores_linear_f1))
    print("Linear time: ", t)

    print("")  
    linear_means_noise_ac.append(mean(scores_linear_ac))
    linear_means_noise_f1.append(mean(scores_linear_f1))


# Cross Validation Poly
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_poly_ac = []
    scores_poly_f1 = []
 
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        poly = svm.SVC(kernel='poly')
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train)
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        poly.fit(X_train, y_train)
        pred_poly = poly.predict(X_test)        
        score_poly_ac = accuracy_score(y_test, pred_poly)
        score_poly_f1 = f1_score(y_test, pred_poly)

        scores_poly_ac.append(score_poly_ac)
        scores_poly_f1.append(score_poly_f1)
    end = time.time()
    t = end-start
    time_poly_sum_bc.append(t)


    print("Noise level: " + str((n+1)*10) + '%')    
    print("Poly accuracy mean is: ", mean(scores_poly_ac))
    print("Poly f1 mean is: ", mean(scores_poly_f1))
    print("Poly time: ", t)

    print("")  
    poly_means_noise_ac.append(mean(scores_poly_ac))
    poly_means_noise_f1.append(mean(scores_poly_f1))


# Cross Validation Rbf
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_rbf_ac = []
    scores_rbf_f1 = []
  
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        rbf = svm.SVC(kernel='rbf')
        
        # Train the models
        #Applying Standard scaling to get optimized result
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        rbf.fit(X_train, y_train)
        pred_rbf = rbf.predict(X_test)
       
        score_rbf_ac = accuracy_score(y_test, pred_rbf)
        score_rbf_f1 = f1_score(y_test, pred_rbf)

        scores_rbf_ac.append(score_rbf_ac)
        scores_rbf_f1.append(score_rbf_f1)
    end = time.time()
    t = end-start
    time_rbf_sum_bc.append(t)
   
    print("Noise level: " + str((n+1)*10) + '%')    
    print("Rbf accuracy mean is: ", mean(scores_rbf_ac))
    print("Rbf f1 mean is: ", mean(scores_rbf_f1))
    print("Rbf time: ", t)

    print("")  
    rbf_means_noise_ac.append(mean(scores_rbf_ac))
    rbf_means_noise_f1.append(mean(scores_rbf_f1))


# Cross Validation ANN
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_ann_ac = []
    scores_ann_f1 = []
    
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        ann = MLPClassifier(hidden_layer_sizes=(10,10,10), max_iter=1000)
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train.ravel())
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        ann.fit(X_train, y_train)
        pred_ann = ann.predict(X_test)
        
        score_ann_ac = accuracy_score(y_test, pred_ann)
        score_ann_f1 = f1_score(y_test, pred_ann)

        scores_ann_ac.append(score_ann_ac)
        scores_ann_f1.append(score_ann_f1)
    end = time.time()
    t = end-start
    time_ann_sum_bc.append(t)
    
    print("Noise level: " + str((n+1)*10) + '%')    
    print("ANN accuracy mean is: ", mean(scores_ann_ac))
    print("ANN f1 mean is: ", mean(scores_ann_f1))
    print("Ann time: ", t)

    print("")  
    ann_means_noise_ac.append(mean(scores_ann_ac))
    ann_means_noise_f1.append(mean(scores_ann_f1))


# Cross Validation RF
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_rf_ac = []
    scores_rf_f1 = []
    
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        rf = RandomForestClassifier(n_estimators=200)
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train.ravel())
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        rf.fit(X_train, y_train)
        pred_rf = rf.predict(X_test)
        
        score_rf_ac = accuracy_score(y_test, pred_rf)
        score_rf_f1 = f1_score(y_test, pred_rf)

        scores_rf_ac.append(score_rf_ac)
        scores_rf_f1.append(score_rf_f1)
    end = time.time()
    t = end-start
    time_rf_sum_bc.append(t)
    
    print("Noise level: " + str((n+1)*10) + '%')    
    print("RF accuracy mean is: ", mean(scores_rf_ac))
    print("RF f1 mean is: ", mean(scores_rf_f1))
    print("Rf time: ", t)

    print("")  
    rf_means_noise_ac.append(mean(scores_rf_ac))
    rf_means_noise_f1.append(mean(scores_rf_f1))


# Make arrays with all the results [noise0, noise10%, noise20%..]
linear_result_ac_bc = linear_means_ac.copy()
poly_result_ac_bc = poly_means_ac.copy()
rbf_result_ac_bc = rbf_means_ac.copy()
ann_result_ac_bc = ann_means_ac.copy()
rf_result_ac_bc = rf_means_ac.copy()

linear_result_f1_bc = linear_means_f1.copy()
poly_result_f1_bc = poly_means_f1.copy()
rbf_result_f1_bc = rbf_means_f1.copy()
ann_result_f1_bc = ann_means_f1.copy()
rf_result_f1_bc = rf_means_f1.copy()

for i in range (10):
    linear_result_ac_bc.append(linear_means_noise_ac[i]) 
    poly_result_ac_bc.append(poly_means_noise_ac[i]) 
    rbf_result_ac_bc.append(rbf_means_noise_ac[i]) 
    ann_result_ac_bc.append(ann_means_noise_ac[i]) 
    rf_result_ac_bc.append(rf_means_noise_ac[i]) 
    
    linear_result_f1_bc.append(linear_means_noise_f1[i]) 
    poly_result_f1_bc.append(poly_means_noise_f1[i]) 
    rbf_result_f1_bc.append(rbf_means_noise_f1[i]) 
    ann_result_f1_bc.append(ann_means_noise_f1[i]) 
    rf_result_f1_bc.append(rf_means_noise_f1[i])
    
# Make ELA
linear_ela_result_bc = []
poly_ela_result_bc = []
rbf_ela_result_bc = []
ann_ela_result_bc = []
rf_ela_result_bc = []

linear_ela_result_bc.append((100-100*linear_means_ac[0])/(100*linear_means_ac[0]))
poly_ela_result_bc.append((100-100*poly_means_ac[0])/(100*poly_means_ac[0]))
rbf_ela_result_bc.append((100-100*rbf_means_ac[0])/(100*rbf_means_ac[0]))
ann_ela_result_bc.append((100-100*ann_means_ac[0])/(100*ann_means_ac[0]))
rf_ela_result_bc.append((100-100*rf_means_ac[0])/(100*rf_means_ac[0]))


for i in range (10):
    linear_ela = (100-100*linear_means_noise_ac[i])/(100*linear_means_ac[0])
    poly_ela = (100-100*poly_means_noise_ac[i])/(100*poly_means_ac[0])
    rbf_ela = (100-100*rbf_means_noise_ac[i])/(100*rbf_means_ac[0])
    ann_ela = (100-100*ann_means_noise_ac[i])/(100*ann_means_ac[0])
    rf_ela = (100-100*rf_means_noise_ac[i])/(100*rf_means_ac[0])
    
    linear_ela_result_bc.append(linear_ela)
    poly_ela_result_bc.append(poly_ela)
    rbf_ela_result_bc.append(rbf_ela)
    ann_ela_result_bc.append(ann_ela)
    rf_ela_result_bc.append(rf_ela)

# Commented out IPython magic to ensure Python compatibility.
# Accuracy Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_result_ac_bc, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, poly_result_ac_bc, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, rbf_result_ac_bc, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, ann_result_ac_bc, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, rf_result_ac_bc, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.legend()

# Commented out IPython magic to ensure Python compatibility.
# F-score Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_result_f1_bc, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, poly_result_f1_bc, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, rbf_result_f1_bc, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, ann_result_f1_bc, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, rf_result_f1_bc, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.legend()

# Commented out IPython magic to ensure Python compatibility.
# ELA Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_ela_result_bc, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, poly_ela_result_bc, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, rbf_ela_result_bc, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, ann_ela_result_bc, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, rf_ela_result_bc, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.legend()

# Commented out IPython magic to ensure Python compatibility.
# Time Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, time_linear_sum_bc, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_poly_sum_bc, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_rbf_sum_bc, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_ann_sum_bc, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_rf_sum_bc, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.legend()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Accuracy  ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_result_ac_bc[0],4),round(poly_result_ac_bc[0],4),round(rbf_result_ac_bc[0],4),round(ann_result_ac_bc[0],4),round(rf_result_ac_bc[0],4)],
                       [round(linear_result_ac_bc[1],4),round(poly_result_ac_bc[1],4),round(rbf_result_ac_bc[1],4),round(ann_result_ac_bc[1],4),round(rf_result_ac_bc[1],4)],
                       [round(linear_result_ac_bc[2],4),round(poly_result_ac_bc[2],4),round(rbf_result_ac_bc[2],4),round(ann_result_ac_bc[2],4),round(rf_result_ac_bc[2],4)],
                       [round(linear_result_ac_bc[3],4),round(poly_result_ac_bc[3],4),round(rbf_result_ac_bc[3],4),round(ann_result_ac_bc[3],4),round(rf_result_ac_bc[3],4)],
                       [round(linear_result_ac_bc[4],4),round(poly_result_ac_bc[4],4),round(rbf_result_ac_bc[4],4),round(ann_result_ac_bc[4],4),round(rf_result_ac_bc[4],4)],
                       [round(linear_result_ac_bc[5],4),round(poly_result_ac_bc[5],4),round(rbf_result_ac_bc[5],4),round(ann_result_ac_bc[5],4),round(rf_result_ac_bc[5],4)],
                       [round(linear_result_ac_bc[6],4),round(poly_result_ac_bc[6],4),round(rbf_result_ac_bc[6],4),round(ann_result_ac_bc[6],4),round(rf_result_ac_bc[6],4)],
                       [round(linear_result_ac_bc[7],4),round(poly_result_ac_bc[7],4),round(rbf_result_ac_bc[7],4),round(ann_result_ac_bc[7],4),round(rf_result_ac_bc[7],4)],
                       [round(linear_result_ac_bc[8],4),round(poly_result_ac_bc[8],4),round(rbf_result_ac_bc[8],4),round(ann_result_ac_bc[8],4),round(rf_result_ac_bc[8],4)],
                       [round(linear_result_ac_bc[9],4),round(poly_result_ac_bc[9],4),round(rbf_result_ac_bc[9],4),round(ann_result_ac_bc[9],4),round(rf_result_ac_bc[9],4)],
                       [round(linear_result_ac_bc[10],4),round(poly_result_ac_bc[10],4),round(rbf_result_ac_bc[10],4),round(ann_result_ac_bc[10],4),round(rf_result_ac_bc[10],4)]
                       ], # 2nd column
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['F-score ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_result_f1_bc[0],4),round(poly_result_f1_bc[0],4),round(rbf_result_f1_bc[0],4),round(ann_result_f1_bc[0],4),round(rf_result_f1_bc[0],4)],
                       [round(linear_result_f1_bc[1],4),round(poly_result_f1_bc[1],4),round(rbf_result_f1_bc[1],4),round(ann_result_f1_bc[1],4),round(rf_result_f1_bc[1],4)],
                       [round(linear_result_f1_bc[2],4),round(poly_result_f1_bc[2],4),round(rbf_result_f1_bc[2],4),round(ann_result_f1_bc[2],4),round(rf_result_f1_bc[2],4)],
                       [round(linear_result_f1_bc[3],4),round(poly_result_f1_bc[3],4),round(rbf_result_f1_bc[3],4),round(ann_result_f1_bc[3],4),round(rf_result_f1_bc[3],4)],
                       [round(linear_result_f1_bc[4],4),round(poly_result_f1_bc[4],4),round(rbf_result_f1_bc[4],4),round(ann_result_f1_bc[4],4),round(rf_result_f1_bc[4],4)],
                       [round(linear_result_f1_bc[5],4),round(poly_result_f1_bc[5],4),round(rbf_result_f1_bc[5],4),round(ann_result_f1_bc[5],4),round(rf_result_f1_bc[5],4)],
                       [round(linear_result_f1_bc[6],4),round(poly_result_f1_bc[6],4),round(rbf_result_f1_bc[6],4),round(ann_result_f1_bc[6],4),round(rf_result_f1_bc[6],4)],
                       [round(linear_result_f1_bc[7],4),round(poly_result_f1_bc[7],4),round(rbf_result_f1_bc[7],4),round(ann_result_f1_bc[7],4),round(rf_result_f1_bc[7],4)],
                       [round(linear_result_f1_bc[8],4),round(poly_result_f1_bc[8],4),round(rbf_result_f1_bc[8],4),round(ann_result_f1_bc[8],4),round(rf_result_f1_bc[8],4)],
                       [round(linear_result_f1_bc[9],4),round(poly_result_f1_bc[9],4),round(rbf_result_f1_bc[9],4),round(ann_result_f1_bc[9],4),round(rf_result_f1_bc[9],4)],
                       [round(linear_result_f1_bc[10],4),round(poly_result__bc[10],4),round(rbf_result_f1_bc[10],4),round(ann_result_f1_bc[10],4),round(rf_result_f1_bc[10],4)]
                       ], # 2nd column
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['ELA ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_ela_result_bc[0],4),round(poly_ela_result_bc[0],4),round(rbf_ela_result_bc[0],4),round(ann_ela_result_bc[0],4),round(rf_ela_result_bc[0],4)],
                       [round(linear_ela_result_bc[1],4),round(poly_ela_result_bc[1],4),round(rbf_ela_result_bc[1],4),round(ann_ela_result_bc[1],4),round(rf_ela_result_bc[1],4)],
                       [round(linear_ela_result_bc[2],4),round(poly_ela_result_bc[2],4),round(rbf_ela_result_bc[2],4),round(ann_ela_result_bc[2],4),round(rf_ela_result_bc[2],4)],
                       [round(linear_ela_result_bc[3],4),round(poly_ela_result_bc[3],4),round(rbf_ela_result_bc[3],4),round(ann_ela_result_bc[3],4),round(rf_ela_result_bc[3],4)],
                       [round(linear_ela_result_bc[4],4),round(poly_ela_result_bc[4],4),round(rbf_ela_result_bc[4],4),round(ann_ela_result_bc[4],4),round(rf_ela_result_bc[4],4)],
                       [round(linear_ela_result_bc[5],4),round(poly_ela_result_bc[5],4),round(rbf_ela_result_bc[5],4),round(ann_ela_result_bc[5],4),round(rf_ela_result_bc[5],4)],
                       [round(linear_ela_result_bc[6],4),round(poly_ela_result_bc[6],4),round(rbf_ela_result_bc[6],4),round(ann_ela_result_bc[6],4),round(rf_ela_result_bc[6],4)],
                       [round(linear_ela_result_bc[7],4),round(poly_ela_result_bc[7],4),round(rbf_ela_result_bc[7],4),round(ann_ela_result_bc[7],4),round(rf_ela_result_bc[7],4)],
                       [round(linear_ela_result_bc[8],4),round(poly_ela_result_bc[8],4),round(rbf_ela_result_bc[8],4),round(ann_ela_result_bc[8],4),round(rf_ela_result_bc[8],4)],
                       [round(linear_ela_result_bc[9],4),round(poly_ela_result_bc[9],4),round(rbf_ela_result_bc[9],4),round(ann_ela_result_bc[9],4),round(rf_ela_result_bc[9],4)],
                       [round(linear_ela_result_bc[10],4),round(poly_ela_result_bc[10],4),round(rbf_ela_result_bc[10],4),round(ann_ela_result_bc[10],4),round(rf_ela_result_bc[10],4)]
                       ], 
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Time (s)',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(time_linear_sum_bc[0],4),round(time_poly_sum_bc[0],4),round(time_rbf_sum_bc[0],4),round(time_ann_sum_bc[0],4),round(time_rf_sum_bc[0],4)],
                       [round(time_linear_sum_bc[1],4),round(time_poly_sum_bc[1],4),round(time_rbf_sum_bc[1],4),round(time_ann_sum_bc[1],4),round(time_rf_sum_bc[1],4)],
                       [round(time_linear_sum_bc[2],4),round(time_poly_sum_bc[2],4),round(time_rbf_sum_bc[2],4),round(time_ann_sum_bc[2],4),round(time_rf_sum_bc[2],4)],
                       [round(time_linear_sum_bc[3],4),round(time_poly_sum_bc[3],4),round(time_rbf_sum_bc[3],4),round(time_ann_sum_bc[3],4),round(time_rf_sum_bc[3],4)],
                       [round(time_linear_sum_bc[4],4),round(time_poly_sum_bc[4],4),round(time_rbf_sum_bc[4],4),round(time_ann_sum_bc[4],4),round(time_rf_sum_bc[4],4)],
                       [round(time_linear_sum_bc[5],4),round(time_poly_sum_bc[5],4),round(time_rbf_sum_bc[5],4),round(time_ann_sum_bc[5],4),round(time_rf_sum_bc[5],4)],
                       [round(time_linear_sum_bc[6],4),round(time_poly_sum_bc[6],4),round(time_rbf_sum_bc[6],4),round(time_ann_sum_bc[6],4),round(time_rf_sum_bc[6],4)],
                       [round(time_linear_sum_bc[7],4),round(time_poly_sum_bc[7],4),round(time_rbf_sum_bc[7],4),round(time_ann_sum_bc[7],4),round(time_rf_sum_bc[7],4)],
                       [round(time_linear_sum_bc[8],4),round(time_poly_sum_bc[8],4),round(time_rbf_sum_bc[8],4),round(time_ann_sum_bc[8],4),round(time_rf_sum_bc[8],4)],
                       [round(time_linear_sum_bc[9],4),round(time_poly_sum_bc[9],4),round(time_rbf_sum_bc[9],4),round(time_ann_sum_bc[9],4),round(time_rf_sum_bc[9],4)],
                       [round(time_linear_sum_bc[10],4),round(time_poly_sum_bc[10],4),round(time_rbf_sum_bc[10],4),round(time_ann_sum_bc[10],4),round(time_rf_sum_bc[10],4)]
                       ], 
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Classifier','Total Time (s)'],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(sum(time_linear_sum_bc),4),round(sum(time_poly_sum_bc),4),round(sum(time_rbf_sum_bc),4),round(sum(time_ann_sum_bc),4),round(sum(time_rf_sum_bc),4)],
                       ], 
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

"""# Banknote"""

#importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns 
import pandas as pd
import math
import time
from sklearn.utils import resample
from imblearn.over_sampling import SMOTE
from statistics import mean
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
from sklearn import svm
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

#Loading datasets
df = pd.read_csv('data_banknote_authentication.csv')
# csv file is modified before loadning

df

# How does the proportion of the Target values look like?
df.banknote.value_counts()

# X,y,etc should be the size which can be divided by n for n-fold cv. Some lows can be discarded. 
cv = 5
# s will be the length of the dataset <= length which can be divided by cv. 
s = math.floor(len(df)/cv)*cv
# d is the size of each partitioned dataset
d = int(s/cv)

X = df.iloc[:s,:-1].values
y = df.iloc[:s,-1].values
X_noise = df.iloc[:s,:-1].values.copy()

# 10 datasets which is going to be noised. 10%, 20% and so on. 
noise = []
n_range = range(0,10)
for n in n_range:
    noise.append(df.iloc[:s,:-1].values.copy())

# Make mean, std, max and min of every column
n_range = range(0, X.shape[1])
mean = []
std = []
max = []
min = []

for n in n_range: 
    mean.append(X_noise[:,n].mean())
    std.append(X_noise[:,n].std())
    max.append(X_noise[:,n].max())
    min.append(X_noise[:,n].min())

# New noise 

m_range = range(1,11)
for m in m_range:
    X_noise = noise[m-1]
    
    #noise_levels are going to be 0.1, 0.2,...1(10%,20%...)
    noise_level = 0.1 * m
    
    #How many entries(rows) in the dataset we want to add noise?
    noise_entries_amount = int(X.size * noise_level) 
    
    #Create an array with random int which represent the rows we are going to add noise on(no duplicate rows)
    r = np.random.choice(X.size, noise_entries_amount, replace=False)
    
    r_range = range(0,r.size)
    for n in r_range:
        entry = r[n]
        row = int(entry/X.shape[1])
        column = entry%X.shape[1]
                
        g_noise = np.random.normal(mean[column], std[column])
        # if the gaussian noise is greater than the max value of the column, we take the max value as noise. 
        if g_noise > max[column]:
            g_noise = max[column]
            X_noise[row][column] = X_noise[row][column] + g_noise
        # if the gaussian noise is smaller than the min value of the column, we take the min value as noise. 
        elif g_noise < 0:
            g_noise = min[column]
            X_noise[row][column] = X_noise[row][column] + g_noise
        else: 
            X_noise[row][column] = X_noise[row][column] + g_noise


X

noise[0]

noise[9]

# p stands for partitioned
X_p = []
y_p = []
# Each [] will contain noised dataset 10%, 20%... which are divided in cv(e.g. 5)
noise_p = [[],[],[],[],[],[],[],[],[],[],]

n_range = range(0,10)
for n in n_range:
    for i in range(0, len(X), d):
            noise_p[n].append(noise[n][i:i + d])
for i in range(0, len(X), d):
            X_p.append(X[i:i + d])
            y_p.append(y[i:i + d])

linear_means_ac = []
poly_means_ac = []
rbf_means_ac = []
ann_means_ac = []
rf_means_ac = []

linear_means_f1 = []
poly_means_f1 = []
rbf_means_f1 = []
ann_means_f1 = []
rf_means_f1 = []

linear_means_noise_ac = []
poly_means_noise_ac = []
rbf_means_noise_ac = []
ann_means_noise_ac = []
rf_means_noise_ac = []

linear_means_noise_f1 = []
poly_means_noise_f1 = []
rbf_means_noise_f1 = []
ann_means_noise_f1 = []
rf_means_noise_f1 = []

time_linear_sum_banknote = []
time_poly_sum_banknote = []
time_rbf_sum_banknote = []
time_ann_sum_banknote = []
time_rf_sum_banknote = []

# Cross Validation noise 0 
from statistics import mean
first = False
scores_linear_ac = []
scores_poly_ac = []
scores_rbf_ac = []
scores_ann_ac = []
scores_rf_ac = []

scores_linear_f1 = []
scores_poly_f1 = []
scores_rbf_f1 = []
scores_ann_f1 = []
scores_rf_f1 = []

time_linear_banknote = []
time_poly_banknote = []
time_rbf_banknote = []
time_ann_banknote = []
time_rf_banknote = []

for i in range(cv):
    start = time.time()
    X_test = X_p[i]
    y_test = y_p[i]
    first = True
    for k in range(cv):
        if k != i:
            if first != True:
                X_train = np.append(X_train, X_p[k], axis=0)
                y_train = np.append(y_train, y_p[k], axis=0)
            else: 
                X_train = X_p[k]
                y_train = y_p[k]
                first = False

        
    # Now all test, train sets are obtained
    linear = svm.SVC(kernel='linear')
    poly = svm.SVC(kernel='poly')
    rbf = svm.SVC(kernel='rbf')
    ann = MLPClassifier(hidden_layer_sizes=(10,10,10), max_iter=1000)
    rf = RandomForestClassifier(n_estimators=200)
        
    # Our data is biased, we can fix this with SMOTE
    #oversample = SMOTE()
    #X_train, y_train = oversample.fit_resample(X_train, y_train)

    # Train the models
    sc = StandardScaler()
    X_train = sc.fit_transform(X_train)
    X_test = sc.transform(X_test)
    end = time.time()
    t = end-start
    
    linear_start = time.time()
    linear.fit(X_train, y_train)
    pred_linear = linear.predict(X_test)        
    score_linear_ac = accuracy_score(y_test, pred_linear)
    score_linear_f1 = f1_score(y_test, pred_linear)
    scores_linear_ac.append(score_linear_ac)
    scores_linear_f1.append(score_linear_f1)
    linear_end = time.time()
    time_linear_banknote.append(t+(linear_end-linear_start))
    
    poly_start = time.time()
    poly.fit(X_train, y_train)
    pred_poly = poly.predict(X_test)        
    score_poly_ac = accuracy_score(y_test, pred_poly)
    score_poly_f1 = f1_score(y_test, pred_poly)
    scores_poly_ac.append(score_poly_ac)
    scores_poly_f1.append(score_poly_f1)
    poly_end = time.time()
    time_poly_banknote.append(t+(poly_end-poly_start))
    
    rbf_start = time.time()
    rbf.fit(X_train, y_train)
    pred_rbf = rbf.predict(X_test)
    score_rbf_ac = accuracy_score(y_test, pred_rbf)
    scores_rbf_ac.append(score_rbf_ac)
    score_rbf_f1 = f1_score(y_test, pred_rbf)
    scores_rbf_f1.append(score_rbf_f1)
    rbf_end = time.time()
    time_rbf_banknote.append(t+(rbf_end-rbf_start))

    ann_start = time.time()
    ann.fit(X_train, y_train)
    pred_ann = ann.predict(X_test)
    score_ann_ac = accuracy_score(y_test, pred_ann)
    scores_ann_ac.append(score_ann_ac)
    score_ann_f1 = f1_score(y_test, pred_ann)
    scores_ann_f1.append(score_ann_f1)
    ann_end = time.time()
    time_ann_banknote.append(t+(ann_end-ann_start))

    rf_start = time.time()
    rf.fit(X_train, y_train)
    pred_rf = rf.predict(X_test)
    score_rf_ac = accuracy_score(y_test, pred_rf)
    scores_rf_ac.append(score_rf_ac)
    score_rf_f1 = f1_score(y_test, pred_rf)
    scores_rf_f1.append(score_rf_f1)
    rf_end = time.time()
    time_rf_banknote.append(t+(rf_end-rf_start))

time_linear_sum_banknote.append(sum(time_linear_banknote))
time_poly_sum_banknote.append(sum(time_poly_banknote))
time_rbf_sum_banknote.append(sum(time_rbf_banknote))
time_ann_sum_banknote.append(sum(time_ann_banknote))
time_rf_sum_banknote.append(sum(time_rf_banknote))

    
print("Noise level 0")    
print("Linear accuracy mean is: ", mean(scores_linear_ac))
print("Linear f1 mean is: ", mean(scores_linear_f1))
print("")  
linear_means_ac.append(mean(scores_linear_ac))   
linear_means_f1.append(mean(scores_linear_f1))     

print("Noise level 0")    
print("Poly accuracy mean is: ", mean(scores_poly_ac))
print("Poly f1 mean is: ", mean(scores_poly_f1))
print("")  
poly_means_ac.append(mean(scores_poly_ac))   
poly_means_f1.append(mean(scores_poly_f1))     

print("Noise level 0")    
print("Rbf accuracy mean is: ", mean(scores_rbf_ac))
print("Rbf f1 mean is: ", mean(scores_rbf_f1))
print("")
rbf_means_ac.append(mean(scores_rbf_ac))
rbf_means_f1.append(mean(scores_rbf_f1))

print("Noise level 0")    
print("ANN accuracy mean is: ", mean(scores_ann_ac))
print("ANN f1 mean is: ", mean(scores_ann_f1))
print("")
ann_means_ac.append(mean(scores_ann_ac))
ann_means_f1.append(mean(scores_ann_f1))

print("Noise level 0")    
print("RF accuracy mean is: ", mean(scores_rf_ac))
print("RF f1 mean is: ", mean(scores_rf_f1))
print("")
rf_means_ac.append(mean(scores_rf_ac))
rf_means_f1.append(mean(scores_rf_f1))

print("Time linear: ", time_linear_sum_banknote[0])
print("Time poly: ", time_poly_sum_banknote[0])
print("Time rbf: ", time_rbf_sum_banknote[0])
print("Time ann: ", time_ann_sum_banknote[0])
print("Time rf: ", time_rf_sum_banknote[0])


# Cross Validation Linear
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_linear_ac = []
    scores_linear_f1 = []
  
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
        
                    
        # Now all test, train sets are obtained
        linear = svm.SVC(kernel='linear')
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train)
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        linear.fit(X_train, y_train)
        pred_linear = linear.predict(X_test)        
        score_linear_ac = accuracy_score(y_test, pred_linear)
        score_linear_f1 = f1_score(y_test, pred_linear)

        scores_linear_ac.append(score_linear_ac)
        scores_linear_f1.append(score_linear_f1)
    end = time.time()
    t = end-start
    time_linear_sum_banknote.append(t)

    print("Noise level: " + str((n+1)*10) + '%')    
    print("Linear accuracy mean is: ", mean(scores_linear_ac))
    print("Linear f1 mean is: ", mean(scores_linear_f1))
    print("Linear time: ", t)

    print("")  
    linear_means_noise_ac.append(mean(scores_linear_ac))
    linear_means_noise_f1.append(mean(scores_linear_f1))


# Cross Validation Poly
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_poly_ac = []
    scores_poly_f1 = []
 
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        poly = svm.SVC(kernel='poly')
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train)
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        poly.fit(X_train, y_train)
        pred_poly = poly.predict(X_test)        
        score_poly_ac = accuracy_score(y_test, pred_poly)
        score_poly_f1 = f1_score(y_test, pred_poly)

        scores_poly_ac.append(score_poly_ac)
        scores_poly_f1.append(score_poly_f1)
    end = time.time()
    t = end-start
    time_poly_sum_banknote.append(t)


    print("Noise level: " + str((n+1)*10) + '%')    
    print("Poly accuracy mean is: ", mean(scores_poly_ac))
    print("Poly f1 mean is: ", mean(scores_poly_f1))
    print("Poly time: ", t)

    print("")  
    poly_means_noise_ac.append(mean(scores_poly_ac))
    poly_means_noise_f1.append(mean(scores_poly_f1))


# Cross Validation Rbf
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_rbf_ac = []
    scores_rbf_f1 = []
  
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        rbf = svm.SVC(kernel='rbf')
        
        # Train the models
        #Applying Standard scaling to get optimized result
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        rbf.fit(X_train, y_train)
        pred_rbf = rbf.predict(X_test)
       
        score_rbf_ac = accuracy_score(y_test, pred_rbf)
        score_rbf_f1 = f1_score(y_test, pred_rbf)

        scores_rbf_ac.append(score_rbf_ac)
        scores_rbf_f1.append(score_rbf_f1)
    end = time.time()
    t = end-start
    time_rbf_sum_banknote.append(t)
   
    print("Noise level: " + str((n+1)*10) + '%')    
    print("Rbf accuracy mean is: ", mean(scores_rbf_ac))
    print("Rbf f1 mean is: ", mean(scores_rbf_f1))
    print("Rbf time: ", t)

    print("")  
    rbf_means_noise_ac.append(mean(scores_rbf_ac))
    rbf_means_noise_f1.append(mean(scores_rbf_f1))


# Cross Validation ANN
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_ann_ac = []
    scores_ann_f1 = []
    
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        ann = MLPClassifier(hidden_layer_sizes=(10,10,10), max_iter=1000)
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train.ravel())
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        ann.fit(X_train, y_train)
        pred_ann = ann.predict(X_test)
        
        score_ann_ac = accuracy_score(y_test, pred_ann)
        score_ann_f1 = f1_score(y_test, pred_ann)

        scores_ann_ac.append(score_ann_ac)
        scores_ann_f1.append(score_ann_f1)
    end = time.time()
    t = end-start
    time_ann_sum_banknote.append(t)
    
    print("Noise level: " + str((n+1)*10) + '%')    
    print("ANN accuracy mean is: ", mean(scores_ann_ac))
    print("ANN f1 mean is: ", mean(scores_ann_f1))
    print("Ann time: ", t)

    print("")  
    ann_means_noise_ac.append(mean(scores_ann_ac))
    ann_means_noise_f1.append(mean(scores_ann_f1))


# Cross Validation RF
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_rf_ac = []
    scores_rf_f1 = []
    
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        rf = RandomForestClassifier(n_estimators=200)
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train.ravel())
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        rf.fit(X_train, y_train)
        pred_rf = rf.predict(X_test)
        
        score_rf_ac = accuracy_score(y_test, pred_rf)
        score_rf_f1 = f1_score(y_test, pred_rf)

        scores_rf_ac.append(score_rf_ac)
        scores_rf_f1.append(score_rf_f1)
    end = time.time()
    t = end-start
    time_rf_sum_banknote.append(t)
    
    print("Noise level: " + str((n+1)*10) + '%')    
    print("RF accuracy mean is: ", mean(scores_rf_ac))
    print("RF f1 mean is: ", mean(scores_rf_f1))
    print("Rf time: ", t)

    print("")  
    rf_means_noise_ac.append(mean(scores_rf_ac))
    rf_means_noise_f1.append(mean(scores_rf_f1))


# Make arrays with all the results [noise0, noise10%, noise20%..]
linear_result_ac_banknote = linear_means_ac.copy()
poly_result_ac_banknote = poly_means_ac.copy()
rbf_result_ac_banknote = rbf_means_ac.copy()
ann_result_ac_banknote = ann_means_ac.copy()
rf_result_ac_banknote = rf_means_ac.copy()

linear_result_f1_banknote = linear_means_f1.copy()
poly_result_f1_banknote = poly_means_f1.copy()
rbf_result_f1_banknote = rbf_means_f1.copy()
ann_result_f1_banknote = ann_means_f1.copy()
rf_result_f1_banknote = rf_means_f1.copy()

for i in range (10):
    linear_result_ac_banknote.append(linear_means_noise_ac[i]) 
    poly_result_ac_banknote.append(poly_means_noise_ac[i]) 
    rbf_result_ac_banknote.append(rbf_means_noise_ac[i]) 
    ann_result_ac_banknote.append(ann_means_noise_ac[i]) 
    rf_result_ac_banknote.append(rf_means_noise_ac[i]) 
    
    linear_result_f1_banknote.append(linear_means_noise_f1[i]) 
    poly_result_f1_banknote.append(poly_means_noise_f1[i]) 
    rbf_result_f1_banknote.append(rbf_means_noise_f1[i]) 
    ann_result_f1_banknote.append(ann_means_noise_f1[i]) 
    rf_result_f1_banknote.append(rf_means_noise_f1[i])
    
# Make ELA
linear_ela_result_banknote = []
poly_ela_result_banknote = []
rbf_ela_result_banknote = []
ann_ela_result_banknote = []
rf_ela_result_banknote = []

linear_ela_result_banknote.append((100-100*linear_means_ac[0])/(100*linear_means_ac[0]))
poly_ela_result_banknote.append((100-100*poly_means_ac[0])/(100*poly_means_ac[0]))
rbf_ela_result_banknote.append((100-100*rbf_means_ac[0])/(100*rbf_means_ac[0]))
ann_ela_result_banknote.append((100-100*ann_means_ac[0])/(100*ann_means_ac[0]))
rf_ela_result_banknote.append((100-100*rf_means_ac[0])/(100*rf_means_ac[0]))


for i in range (10):
    linear_ela = (100-100*linear_means_noise_ac[i])/(100*linear_means_ac[0])
    poly_ela = (100-100*poly_means_noise_ac[i])/(100*poly_means_ac[0])
    rbf_ela = (100-100*rbf_means_noise_ac[i])/(100*rbf_means_ac[0])
    ann_ela = (100-100*ann_means_noise_ac[i])/(100*ann_means_ac[0])
    rf_ela = (100-100*rf_means_noise_ac[i])/(100*rf_means_ac[0])
    
    linear_ela_result_banknote.append(linear_ela)
    poly_ela_result_banknote.append(poly_ela)
    rbf_ela_result_banknote.append(rbf_ela)
    ann_ela_result_banknote.append(ann_ela)
    rf_ela_result_banknote.append(rf_ela)

# Commented out IPython magic to ensure Python compatibility.
# Accuracy Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_result_ac_banknote, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, poly_result_ac_banknote, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, rbf_result_ac_banknote, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, ann_result_ac_banknote, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, rf_result_ac_banknote, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.legend()

# Commented out IPython magic to ensure Python compatibility.
# F1-score Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_result_f1_banknote, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, poly_result_f1_banknote, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, rbf_result_f1_banknote, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, ann_result_f1_banknote, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, rf_result_f1_banknote, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.legend()

# Commented out IPython magic to ensure Python compatibility.
# ELA Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_ela_result_banknote, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, poly_ela_result_banknote, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, rbf_ela_result_banknote, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, ann_ela_result_banknote, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, rf_ela_result_banknote, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.legend()

# Commented out IPython magic to ensure Python compatibility.
# Time Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, time_linear_sum_banknote, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_poly_sum_banknote, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_rbf_sum_banknote, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_ann_sum_banknote, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_rf_sum_banknote, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.legend()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Accuracy  ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_result_ac_banknote[0],4),round(poly_result_ac_banknote[0],4),round(rbf_result_ac_banknote[0],4),round(ann_result_ac_banknote[0],4),round(rf_result_ac_banknote[0],4)],
                       [round(linear_result_ac_banknote[1],4),round(poly_result_ac_banknote[1],4),round(rbf_result_ac_banknote[1],4),round(ann_result_ac_banknote[1],4),round(rf_result_ac_banknote[1],4)],
                       [round(linear_result_ac_banknote[2],4),round(poly_result_ac_banknote[2],4),round(rbf_result_ac_banknote[2],4),round(ann_result_ac_banknote[2],4),round(rf_result_ac_banknote[2],4)],
                       [round(linear_result_ac_banknote[3],4),round(poly_result_ac_banknote[3],4),round(rbf_result_ac_banknote[3],4),round(ann_result_ac_banknote[3],4),round(rf_result_ac_banknote[3],4)],
                       [round(linear_result_ac_banknote[4],4),round(poly_result_ac_banknote[4],4),round(rbf_result_ac_banknote[4],4),round(ann_result_ac_banknote[4],4),round(rf_result_ac_banknote[4],4)],
                       [round(linear_result_ac_banknote[5],4),round(poly_result_ac_banknote[5],4),round(rbf_result_ac_banknote[5],4),round(ann_result_ac_banknote[5],4),round(rf_result_ac_banknote[5],4)],
                       [round(linear_result_ac_banknote[6],4),round(poly_result_ac_banknote[6],4),round(rbf_result_ac_banknote[6],4),round(ann_result_ac_banknote[6],4),round(rf_result_ac_banknote[6],4)],
                       [round(linear_result_ac_banknote[7],4),round(poly_result_ac_banknote[7],4),round(rbf_result_ac_banknote[7],4),round(ann_result_ac_banknote[7],4),round(rf_result_ac_banknote[7],4)],
                       [round(linear_result_ac_banknote[8],4),round(poly_result_ac_banknote[8],4),round(rbf_result_ac_banknote[8],4),round(ann_result_ac_banknote[8],4),round(rf_result_ac_banknote[8],4)],
                       [round(linear_result_ac_banknote[9],4),round(poly_result_ac_banknote[9],4),round(rbf_result_ac_banknote[9],4),round(ann_result_ac_banknote[9],4),round(rf_result_ac_banknote[9],4)],
                       [round(linear_result_ac_banknote[10],4),round(poly_result_ac_banknote[10],4),round(rbf_result_ac_banknote[10],4),round(ann_result_ac_banknote[10],4),round(rf_result_ac_banknote[10],4)]
                       ], # 2nd column
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['F-score ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_result_f1_banknote[0],4),round(poly_result_f1_banknote[0],4),round(rbf_result_f1_banknote[0],4),round(ann_result_f1_banknote[0],4),round(rf_result_f1_banknote[0],4)],
                       [round(linear_result_f1_banknote[1],4),round(poly_result_f1_banknote[1],4),round(rbf_result_f1_banknote[1],4),round(ann_result_f1_banknote[1],4),round(rf_result_f1_banknote[1],4)],
                       [round(linear_result_f1_banknote[2],4),round(poly_result_f1_banknote[2],4),round(rbf_result_f1_banknote[2],4),round(ann_result_f1_banknote[2],4),round(rf_result_f1_banknote[2],4)],
                       [round(linear_result_f1_banknote[3],4),round(poly_result_f1_banknote[3],4),round(rbf_result_f1_banknote[3],4),round(ann_result_f1_banknote[3],4),round(rf_result_f1_banknote[3],4)],
                       [round(linear_result_f1_banknote[4],4),round(poly_result_f1_banknote[4],4),round(rbf_result_f1_banknote[4],4),round(ann_result_f1_banknote[4],4),round(rf_result_f1_banknote[4],4)],
                       [round(linear_result_f1_banknote[5],4),round(poly_result_f1_banknote[5],4),round(rbf_result_f1_banknote[5],4),round(ann_result_f1_banknote[5],4),round(rf_result_f1_banknote[5],4)],
                       [round(linear_result_f1_banknote[6],4),round(poly_result_f1_banknote[6],4),round(rbf_result_f1_banknote[6],4),round(ann_result_f1_banknote[6],4),round(rf_result_f1_banknote[6],4)],
                       [round(linear_result_f1_banknote[7],4),round(poly_result_f1_banknote[7],4),round(rbf_result_f1_banknote[7],4),round(ann_result_f1_banknote[7],4),round(rf_result_f1_banknote[7],4)],
                       [round(linear_result_f1_banknote[8],4),round(poly_result_f1_banknote[8],4),round(rbf_result_f1_banknote[8],4),round(ann_result_f1_banknote[8],4),round(rf_result_f1_banknote[8],4)],
                       [round(linear_result_f1_banknote[9],4),round(poly_result_f1_banknote[9],4),round(rbf_result_f1_banknote[9],4),round(ann_result_f1_banknote[9],4),round(rf_result_f1_banknote[9],4)],
                       [round(linear_result_f1_banknote[10],4),round(poly_result_f1_banknote[10],4),round(rbf_result_f1_banknote[10],4),round(ann_result_f1_banknote[10],4),round(rf_result_f1_banknote[10],4)]
                       ], # 2nd column
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['ELA ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_ela_result_banknote[0],4),round(poly_ela_result_banknote[0],4),round(rbf_ela_result_banknote[0],4),round(ann_ela_result_banknote[0],4),round(rf_ela_result_banknote[0],4)],
                       [round(linear_ela_result_banknote[1],4),round(poly_ela_result_banknote[1],4),round(rbf_ela_result_banknote[1],4),round(ann_ela_result_banknote[1],4),round(rf_ela_result_banknote[1],4)],
                       [round(linear_ela_result_banknote[2],4),round(poly_ela_result_banknote[2],4),round(rbf_ela_result_banknote[2],4),round(ann_ela_result_banknote[2],4),round(rf_ela_result_banknote[2],4)],
                       [round(linear_ela_result_banknote[3],4),round(poly_ela_result_banknote[3],4),round(rbf_ela_result_banknote[3],4),round(ann_ela_result_banknote[3],4),round(rf_ela_result_banknote[3],4)],
                       [round(linear_ela_result_banknote[4],4),round(poly_ela_result_banknote[4],4),round(rbf_ela_result_banknote[4],4),round(ann_ela_result_banknote[4],4),round(rf_ela_result_banknote[4],4)],
                       [round(linear_ela_result_banknote[5],4),round(poly_ela_result_banknote[5],4),round(rbf_ela_result_banknote[5],4),round(ann_ela_result_banknote[5],4),round(rf_ela_result_banknote[5],4)],
                       [round(linear_ela_result_banknote[6],4),round(poly_ela_result_banknote[6],4),round(rbf_ela_result_banknote[6],4),round(ann_ela_result_banknote[6],4),round(rf_ela_result_banknote[6],4)],
                       [round(linear_ela_result_banknote[7],4),round(poly_ela_result_banknote[7],4),round(rbf_ela_result_banknote[7],4),round(ann_ela_result_banknote[7],4),round(rf_ela_result_banknote[7],4)],
                       [round(linear_ela_result_banknote[8],4),round(poly_ela_result_banknote[8],4),round(rbf_ela_result_banknote[8],4),round(ann_ela_result_banknote[8],4),round(rf_ela_result_banknote[8],4)],
                       [round(linear_ela_result_banknote[9],4),round(poly_ela_result_banknote[9],4),round(rbf_ela_result_banknote[9],4),round(ann_ela_result_banknote[9],4),round(rf_ela_result_banknote[9],4)],
                       [round(linear_ela_result_banknote[10],4),round(poly_ela_result_banknote[10],4),round(rbf_ela_result_banknote[10],4),round(ann_ela_result_banknote[10],4),round(rf_ela_result_banknote[10],4)]
                       ], 
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Time (s)',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(time_linear_sum_banknote[0],4),round(time_poly_sum_banknote[0],4),round(time_rbf_sum_banknote[0],4),round(time_ann_sum_banknote[0],4),round(time_rf_sum_banknote[0],4)],
                       [round(time_linear_sum_banknote[1],4),round(time_poly_sum_banknote[1],4),round(time_rbf_sum_banknote[1],4),round(time_ann_sum_banknote[1],4),round(time_rf_sum_banknote[1],4)],
                       [round(time_linear_sum_banknote[2],4),round(time_poly_sum_banknote[2],4),round(time_rbf_sum_banknote[2],4),round(time_ann_sum_banknote[2],4),round(time_rf_sum_banknote[2],4)],
                       [round(time_linear_sum_banknote[3],4),round(time_poly_sum_banknote[3],4),round(time_rbf_sum_banknote[3],4),round(time_ann_sum_banknote[3],4),round(time_rf_sum_banknote[3],4)],
                       [round(time_linear_sum_banknote[4],4),round(time_poly_sum_banknote[4],4),round(time_rbf_sum_banknote[4],4),round(time_ann_sum_banknote[4],4),round(time_rf_sum_banknote[4],4)],
                       [round(time_linear_sum_banknote[5],4),round(time_poly_sum_banknote[5],4),round(time_rbf_sum_banknote[5],4),round(time_ann_sum_banknote[5],4),round(time_rf_sum_banknote[5],4)],
                       [round(time_linear_sum_banknote[6],4),round(time_poly_sum_banknote[6],4),round(time_rbf_sum_banknote[6],4),round(time_ann_sum_banknote[6],4),round(time_rf_sum_banknote[6],4)],
                       [round(time_linear_sum_banknote[7],4),round(time_poly_sum_banknote[7],4),round(time_rbf_sum_banknote[7],4),round(time_ann_sum_banknote[7],4),round(time_rf_sum_banknote[7],4)],
                       [round(time_linear_sum_banknote[8],4),round(time_poly_sum_banknote[8],4),round(time_rbf_sum_banknote[8],4),round(time_ann_sum_banknote[8],4),round(time_rf_sum_banknote[8],4)],
                       [round(time_linear_sum_banknote[9],4),round(time_poly_sum_banknote[9],4),round(time_rbf_sum_banknote[9],4),round(time_ann_sum_banknote[9],4),round(time_rf_sum_banknote[9],4)],
                       [round(time_linear_sum_banknote[10],4),round(time_poly_sum_banknote[10],4),round(time_rbf_sum_banknote[10],4),round(time_ann_sum_banknote[10],4),round(time_rf_sum_banknote[10],4)]
                       ], 
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Classifier','Total Time (s)'],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(sum(time_linear_sum_banknote),4),round(sum(time_poly_sum_banknote),4),round(sum(time_rbf_sum_banknote),4),round(sum(time_ann_sum_banknote),4),round(sum(time_rf_sum_banknote),4)],
                       ], 
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

"""# Diabetes"""

#importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns 
import pandas as pd
import math
import time
from sklearn.utils import resample
from imblearn.over_sampling import SMOTE
from statistics import mean
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
from sklearn import svm
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

#Loading datasets
df = pd.read_csv('pima-indians-diabetes.csv')
# drop the id columns
#df = df.drop(['id'],axis=1)

df

# How does the proportion of the Target values look like?
df.c9.value_counts()

# X,y,etc should be the size which can be divided by n for n-fold cv. Some lows can be discarded. 
cv = 5
# s will be the length of the dataset <= length which can be divided by cv. 
s = math.floor(len(df)/cv)*cv
# d is the size of each partitioned dataset
d = int(s/cv)

X = df.iloc[:s,:-1].values
y = df.iloc[:s,-1].values
X_noise = df.iloc[:s,:-1].values.copy()

# 10 datasets which is going to be noised. 10%, 20% and so on. 
noise = []
n_range = range(0,10)
for n in n_range:
    noise.append(df.iloc[:s,:-1].values.copy())

ages = df.iloc[:s,7].unique()

ages[51]

ages.shape

# Make mean, std, max and min of every column
n_range = range(0, X.shape[1])
mean = []
std = []
max = []
min = []

for n in n_range: 
    mean.append(X_noise[:,n].mean())
    std.append(X_noise[:,n].std())
    max.append(X_noise[:,n].max())
    min.append(X_noise[:,n].min())

# New noise 

m_range = range(1,11)
for m in m_range:
    X_noise = noise[m-1]
    
    #noise_levels are going to be 0.1, 0.2,...1(10%,20%...)
    noise_level = 0.1 * m
    
    #How many entries(rows) in the dataset we want to add noise?
    noise_entries_amount = int(X.size * noise_level) 
    
    #Create an array with random int which represent the rows we are going to add noise on(no duplicate rows)
    r = np.random.choice(X.size, noise_entries_amount, replace=False)
    
    r_range = range(0,r.size)
    for n in r_range:
        entry = r[n]
        row = int(entry/X.shape[1])
        column = entry%X.shape[1]
        
        if column == 7:
            while True:
                a = np.random.randint(0, 52)
                if X_noise[row][column] != ages[a]:
                    X_noise[row][column] = ages[a].copy()
                    break
        else:   
            g_noise = np.random.normal(mean[column], std[column])
            # if the gaussian noise is greater than the max value of the column, we take the max value as noise. 
            if g_noise > max[column]:
                g_noise = max[column]
                X_noise[row][column] = X_noise[row][column] + g_noise
            # if the gaussian noise is smaller than the min value of the column, we take the min value as noise. 
            elif g_noise < 0:
                g_noise = min[column]
                X_noise[row][column] = X_noise[row][column] + g_noise
            else: 
                X_noise[row][column] = X_noise[row][column] + g_noise


X

noise[0]

noise[9]

X[:20,7]

noise[9][:20,7]

# p stands for partitioned
X_p = []
y_p = []
# Each [] will contain noised dataset 10%, 20%... which are divided in cv(e.g. 5)
noise_p = [[],[],[],[],[],[],[],[],[],[],]

n_range = range(0,10)
for n in n_range:
    for i in range(0, len(X), d):
            noise_p[n].append(noise[n][i:i + d])
for i in range(0, len(X), d):
            X_p.append(X[i:i + d])
            y_p.append(y[i:i + d])

linear_means_ac = []
poly_means_ac = []
rbf_means_ac = []
ann_means_ac = []
rf_means_ac = []

linear_means_f1 = []
poly_means_f1 = []
rbf_means_f1 = []
ann_means_f1 = []
rf_means_f1 = []

linear_means_noise_ac = []
poly_means_noise_ac = []
rbf_means_noise_ac = []
ann_means_noise_ac = []
rf_means_noise_ac = []

linear_means_noise_f1 = []
poly_means_noise_f1 = []
rbf_means_noise_f1 = []
ann_means_noise_f1 = []
rf_means_noise_f1 = []

time_linear_sum_diabetes = []
time_poly_sum_diabetes = []
time_rbf_sum_diabetes = []
time_ann_sum_diabetes = []
time_rf_sum_diabetes = []

# Cross Validation noise 0 
from statistics import mean
first = False
scores_linear_ac = []
scores_poly_ac = []
scores_rbf_ac = []
scores_ann_ac = []
scores_rf_ac = []

scores_linear_f1 = []
scores_poly_f1 = []
scores_rbf_f1 = []
scores_ann_f1 = []
scores_rf_f1 = []

time_linear_diabetes = []
time_poly_diabetes = []
time_rbf_diabetes = []
time_ann_diabetes = []
time_rf_diabetes = []

for i in range(cv):
    start = time.time()
    X_test = X_p[i]
    y_test = y_p[i]
    first = True
    for k in range(cv):
        if k != i:
            if first != True:
                X_train = np.append(X_train, X_p[k], axis=0)
                y_train = np.append(y_train, y_p[k], axis=0)
            else: 
                X_train = X_p[k]
                y_train = y_p[k]
                first = False

        
    # Now all test, train sets are obtained
    linear = svm.SVC(kernel='linear')
    poly = svm.SVC(kernel='poly')
    rbf = svm.SVC(kernel='rbf')
    ann = MLPClassifier(hidden_layer_sizes=(10,10,10), max_iter=1000)
    rf = RandomForestClassifier(n_estimators=200)
        
    # Our data is biased, we can fix this with SMOTE
    #oversample = SMOTE()
    #X_train, y_train = oversample.fit_resample(X_train, y_train)

    # Train the models
    sc = StandardScaler()
    X_train = sc.fit_transform(X_train)
    X_test = sc.transform(X_test)
    end = time.time()
    t = end-start
    
    linear_start = time.time()
    linear.fit(X_train, y_train)
    pred_linear = linear.predict(X_test)        
    score_linear_ac = accuracy_score(y_test, pred_linear)
    score_linear_f1 = f1_score(y_test, pred_linear)
    scores_linear_ac.append(score_linear_ac)
    scores_linear_f1.append(score_linear_f1)
    linear_end = time.time()
    time_linear_diabetes.append(t+(linear_end-linear_start))
    
    poly_start = time.time()
    poly.fit(X_train, y_train)
    pred_poly = poly.predict(X_test)        
    score_poly_ac = accuracy_score(y_test, pred_poly)
    score_poly_f1 = f1_score(y_test, pred_poly)
    scores_poly_ac.append(score_poly_ac)
    scores_poly_f1.append(score_poly_f1)
    poly_end = time.time()
    time_poly_diabetes.append(t+(poly_end-poly_start))
    
    rbf_start = time.time()
    rbf.fit(X_train, y_train)
    pred_rbf = rbf.predict(X_test)
    score_rbf_ac = accuracy_score(y_test, pred_rbf)
    scores_rbf_ac.append(score_rbf_ac)
    score_rbf_f1 = f1_score(y_test, pred_rbf)
    scores_rbf_f1.append(score_rbf_f1)
    rbf_end = time.time()
    time_rbf_diabetes.append(t+(rbf_end-rbf_start))

    ann_start = time.time()
    ann.fit(X_train, y_train)
    pred_ann = ann.predict(X_test)
    score_ann_ac = accuracy_score(y_test, pred_ann)
    scores_ann_ac.append(score_ann_ac)
    score_ann_f1 = f1_score(y_test, pred_ann)
    scores_ann_f1.append(score_ann_f1)
    ann_end = time.time()
    time_ann_diabetes.append(t+(ann_end-ann_start))

    rf_start = time.time()
    rf.fit(X_train, y_train)
    pred_rf = rf.predict(X_test)
    score_rf_ac = accuracy_score(y_test, pred_rf)
    scores_rf_ac.append(score_rf_ac)
    score_rf_f1 = f1_score(y_test, pred_rf)
    scores_rf_f1.append(score_rf_f1)
    rf_end = time.time()
    time_rf_diabetes.append(t+(rf_end-rf_start))

time_linear_sum_diabetes.append(sum(time_linear_diabetes))
time_poly_sum_diabetes.append(sum(time_poly_diabetes))
time_rbf_sum_diabetes.append(sum(time_rbf_diabetes))
time_ann_sum_diabetes.append(sum(time_ann_diabetes))
time_rf_sum_diabetes.append(sum(time_rf_diabetes))

    
print("Noise level 0")    
print("Linear accuracy mean is: ", mean(scores_linear_ac))
print("Linear f1 mean is: ", mean(scores_linear_f1))
print("")  
linear_means_ac.append(mean(scores_linear_ac))   
linear_means_f1.append(mean(scores_linear_f1))     

print("Noise level 0")    
print("Poly accuracy mean is: ", mean(scores_poly_ac))
print("Poly f1 mean is: ", mean(scores_poly_f1))
print("")  
poly_means_ac.append(mean(scores_poly_ac))   
poly_means_f1.append(mean(scores_poly_f1))     

print("Noise level 0")    
print("Rbf accuracy mean is: ", mean(scores_rbf_ac))
print("Rbf f1 mean is: ", mean(scores_rbf_f1))
print("")
rbf_means_ac.append(mean(scores_rbf_ac))
rbf_means_f1.append(mean(scores_rbf_f1))

print("Noise level 0")    
print("ANN accuracy mean is: ", mean(scores_ann_ac))
print("ANN f1 mean is: ", mean(scores_ann_f1))
print("")
ann_means_ac.append(mean(scores_ann_ac))
ann_means_f1.append(mean(scores_ann_f1))

print("Noise level 0")    
print("RF accuracy mean is: ", mean(scores_rf_ac))
print("RF f1 mean is: ", mean(scores_rf_f1))
print("")
rf_means_ac.append(mean(scores_rf_ac))
rf_means_f1.append(mean(scores_rf_f1))

print("Time linear: ", time_linear_sum_diabetes[0])
print("Time poly: ", time_poly_sum_diabetes[0])
print("Time rbf: ", time_rbf_sum_diabetes[0])
print("Time ann: ", time_ann_sum_diabetes[0])
print("Time rf: ", time_rf_sum_diabetes[0])


# Cross Validation Linear
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_linear_ac = []
    scores_linear_f1 = []
  
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
        
                    
        # Now all test, train sets are obtained
        linear = svm.SVC(kernel='linear')
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train)
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        linear.fit(X_train, y_train)
        pred_linear = linear.predict(X_test)        
        score_linear_ac = accuracy_score(y_test, pred_linear)
        score_linear_f1 = f1_score(y_test, pred_linear)

        scores_linear_ac.append(score_linear_ac)
        scores_linear_f1.append(score_linear_f1)
    end = time.time()
    t = end-start
    time_linear_sum_diabetes.append(t)

    print("Noise level: " + str((n+1)*10) + '%')    
    print("Linear accuracy mean is: ", mean(scores_linear_ac))
    print("Linear f1 mean is: ", mean(scores_linear_f1))
    print("Linear time: ", t)

    print("")  
    linear_means_noise_ac.append(mean(scores_linear_ac))
    linear_means_noise_f1.append(mean(scores_linear_f1))


# Cross Validation Poly
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_poly_ac = []
    scores_poly_f1 = []
 
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        poly = svm.SVC(kernel='poly')
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train)
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        poly.fit(X_train, y_train)
        pred_poly = poly.predict(X_test)        
        score_poly_ac = accuracy_score(y_test, pred_poly)
        score_poly_f1 = f1_score(y_test, pred_poly)

        scores_poly_ac.append(score_poly_ac)
        scores_poly_f1.append(score_poly_f1)
    end = time.time()
    t = end-start
    time_poly_sum_diabetes.append(t)


    print("Noise level: " + str((n+1)*10) + '%')    
    print("Poly accuracy mean is: ", mean(scores_poly_ac))
    print("Poly f1 mean is: ", mean(scores_poly_f1))
    print("Poly time: ", t)

    print("")  
    poly_means_noise_ac.append(mean(scores_poly_ac))
    poly_means_noise_f1.append(mean(scores_poly_f1))


# Cross Validation Rbf
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_rbf_ac = []
    scores_rbf_f1 = []
  
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        rbf = svm.SVC(kernel='rbf')
        
        # Train the models
        #Applying Standard scaling to get optimized result
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        rbf.fit(X_train, y_train)
        pred_rbf = rbf.predict(X_test)
       
        score_rbf_ac = accuracy_score(y_test, pred_rbf)
        score_rbf_f1 = f1_score(y_test, pred_rbf)

        scores_rbf_ac.append(score_rbf_ac)
        scores_rbf_f1.append(score_rbf_f1)
    end = time.time()
    t = end-start
    time_rbf_sum_diabetes.append(t)
   
    print("Noise level: " + str((n+1)*10) + '%')    
    print("Rbf accuracy mean is: ", mean(scores_rbf_ac))
    print("Rbf f1 mean is: ", mean(scores_rbf_f1))
    print("Rbf time: ", t)

    print("")  
    rbf_means_noise_ac.append(mean(scores_rbf_ac))
    rbf_means_noise_f1.append(mean(scores_rbf_f1))


# Cross Validation ANN
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_ann_ac = []
    scores_ann_f1 = []
    
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        ann = MLPClassifier(hidden_layer_sizes=(10,10,10), max_iter=1000)
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train.ravel())
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        ann.fit(X_train, y_train)
        pred_ann = ann.predict(X_test)
        
        score_ann_ac = accuracy_score(y_test, pred_ann)
        score_ann_f1 = f1_score(y_test, pred_ann)

        scores_ann_ac.append(score_ann_ac)
        scores_ann_f1.append(score_ann_f1)
    end = time.time()
    t = end-start
    time_ann_sum_diabetes.append(t)
    
    print("Noise level: " + str((n+1)*10) + '%')    
    print("ANN accuracy mean is: ", mean(scores_ann_ac))
    print("ANN f1 mean is: ", mean(scores_ann_f1))
    print("Ann time: ", t)

    print("")  
    ann_means_noise_ac.append(mean(scores_ann_ac))
    ann_means_noise_f1.append(mean(scores_ann_f1))


# Cross Validation RF
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_rf_ac = []
    scores_rf_f1 = []
    
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        rf = RandomForestClassifier(n_estimators=200)
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train.ravel())
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        rf.fit(X_train, y_train)
        pred_rf = rf.predict(X_test)
        
        score_rf_ac = accuracy_score(y_test, pred_rf)
        score_rf_f1 = f1_score(y_test, pred_rf)

        scores_rf_ac.append(score_rf_ac)
        scores_rf_f1.append(score_rf_f1)
    end = time.time()
    t = end-start
    time_rf_sum_diabetes.append(t)
    
    print("Noise level: " + str((n+1)*10) + '%')    
    print("RF accuracy mean is: ", mean(scores_rf_ac))
    print("RF f1 mean is: ", mean(scores_rf_f1))
    print("Rf time: ", t)

    print("")  
    rf_means_noise_ac.append(mean(scores_rf_ac))
    rf_means_noise_f1.append(mean(scores_rf_f1))


# Make arrays with all the results [noise0, noise10%, noise20%..]
linear_result_ac_diabetes = linear_means_ac.copy()
poly_result_ac_diabetes = poly_means_ac.copy()
rbf_result_ac_diabetes = rbf_means_ac.copy()
ann_result_ac_diabetes = ann_means_ac.copy()
rf_result_ac_diabetes = rf_means_ac.copy()

linear_result_f1_diabetes = linear_means_f1.copy()
poly_result_f1_diabetes = poly_means_f1.copy()
rbf_result_f1_diabetes = rbf_means_f1.copy()
ann_result_f1_diabetes = ann_means_f1.copy()
rf_result_f1_diabetes = rf_means_f1.copy()

for i in range (10):
    linear_result_ac_diabetes.append(linear_means_noise_ac[i]) 
    poly_result_ac_diabetes.append(poly_means_noise_ac[i]) 
    rbf_result_ac_diabetes.append(rbf_means_noise_ac[i]) 
    ann_result_ac_diabetes.append(ann_means_noise_ac[i]) 
    rf_result_ac_diabetes.append(rf_means_noise_ac[i]) 
    
    linear_result_f1_diabetes.append(linear_means_noise_f1[i]) 
    poly_result_f1_diabetes.append(poly_means_noise_f1[i]) 
    rbf_result_f1_diabetes.append(rbf_means_noise_f1[i]) 
    ann_result_f1_diabetes.append(ann_means_noise_f1[i]) 
    rf_result_f1_diabetes.append(rf_means_noise_f1[i])
    
# Make ELA
linear_ela_result_diabetes = []
poly_ela_result_diabetes = []
rbf_ela_result_diabetes = []
ann_ela_result_diabetes = []
rf_ela_result_diabetes = []

linear_ela_result_diabetes.append((100-100*linear_means_ac[0])/(100*linear_means_ac[0]))
poly_ela_result_diabetes.append((100-100*poly_means_ac[0])/(100*poly_means_ac[0]))
rbf_ela_result_diabetes.append((100-100*rbf_means_ac[0])/(100*rbf_means_ac[0]))
ann_ela_result_diabetes.append((100-100*ann_means_ac[0])/(100*ann_means_ac[0]))
rf_ela_result_diabetes.append((100-100*rf_means_ac[0])/(100*rf_means_ac[0]))


for i in range (10):
    linear_ela = (100-100*linear_means_noise_ac[i])/(100*linear_means_ac[0])
    poly_ela = (100-100*poly_means_noise_ac[i])/(100*poly_means_ac[0])
    rbf_ela = (100-100*rbf_means_noise_ac[i])/(100*rbf_means_ac[0])
    ann_ela = (100-100*ann_means_noise_ac[i])/(100*ann_means_ac[0])
    rf_ela = (100-100*rf_means_noise_ac[i])/(100*rf_means_ac[0])
    
    linear_ela_result_diabetes.append(linear_ela)
    poly_ela_result_diabetes.append(poly_ela)
    rbf_ela_result_diabetes.append(rbf_ela)
    ann_ela_result_diabetes.append(ann_ela)
    rf_ela_result_diabetes.append(rf_ela)

# Commented out IPython magic to ensure Python compatibility.
# Accuracy Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_result_ac_diabetes, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, poly_result_ac_diabetes, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, rbf_result_ac_diabetes, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, ann_result_ac_diabetes, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, rf_result_ac_diabetes, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.legend()

# Commented out IPython magic to ensure Python compatibility.
# F1-score Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_result_f1_diabetes, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, poly_result_f1_diabetes, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, rbf_result_f1_diabetes, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, ann_result_f1_diabetes, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, rf_result_f1_diabetes, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.legend()

# Commented out IPython magic to ensure Python compatibility.
# ELA Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_ela_result_diabetes, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, poly_ela_result_diabetes, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, rbf_ela_result_diabetes, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, ann_ela_result_diabetes, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, rf_ela_result_diabetes, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.legend()

# Commented out IPython magic to ensure Python compatibility.
# Time Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, time_linear_sum_diabetes, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_poly_sum_diabetes, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_rbf_sum_diabetes, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_ann_sum_diabetes, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_rf_sum_diabetes, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.legend()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Accuracy  ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_result_ac_diabetes[0],4),round(poly_result_ac_diabetes[0],4),round(rbf_result_ac_diabetes[0],4),round(ann_result_ac_diabetes[0],4),round(rf_result_ac_diabetes[0],4)],
                       [round(linear_result_ac_diabetes[1],4),round(poly_result_ac_diabetes[1],4),round(rbf_result_ac_diabetes[1],4),round(ann_result_ac_diabetes[1],4),round(rf_result_ac_diabetes[1],4)],
                       [round(linear_result_ac_diabetes[2],4),round(poly_result_ac_diabetes[2],4),round(rbf_result_ac_diabetes[2],4),round(ann_result_ac_diabetes[2],4),round(rf_result_ac_diabetes[2],4)],
                       [round(linear_result_ac_diabetes[3],4),round(poly_result_ac_diabetes[3],4),round(rbf_result_ac_diabetes[3],4),round(ann_result_ac_diabetes[3],4),round(rf_result_ac_diabetes[3],4)],
                       [round(linear_result_ac_diabetes[4],4),round(poly_result_ac_diabetes[4],4),round(rbf_result_ac_diabetes[4],4),round(ann_result_ac_diabetes[4],4),round(rf_result_ac_diabetes[4],4)],
                       [round(linear_result_ac_diabetes[5],4),round(poly_result_ac_diabetes[5],4),round(rbf_result_ac_diabetes[5],4),round(ann_result_ac_diabetes[5],4),round(rf_result_ac_diabetes[5],4)],
                       [round(linear_result_ac_diabetes[6],4),round(poly_result_ac_diabetes[6],4),round(rbf_result_ac_diabetes[6],4),round(ann_result_ac_diabetes[6],4),round(rf_result_ac_diabetes[6],4)],
                       [round(linear_result_ac_diabetes[7],4),round(poly_result_ac_diabetes[7],4),round(rbf_result_ac_diabetes[7],4),round(ann_result_ac_diabetes[7],4),round(rf_result_ac_diabetes[7],4)],
                       [round(linear_result_ac_diabetes[8],4),round(poly_result_ac_diabetes[8],4),round(rbf_result_ac_diabetes[8],4),round(ann_result_ac_diabetes[8],4),round(rf_result_ac_diabetes[8],4)],
                       [round(linear_result_ac_diabetes[9],4),round(poly_result_ac_diabetes[9],4),round(rbf_result_ac_diabetes[9],4),round(ann_result_ac_diabetes[9],4),round(rf_result_ac_diabetes[9],4)],
                       [round(linear_result_ac_diabetes[10],4),round(poly_result_ac_diabetes[10],4),round(rbf_result_ac_diabetes[10],4),round(ann_result_ac_diabetes[10],4),round(rf_result_ac_diabetes[10],4)]
                       ], # 2nd column
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['F1-score ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_result_f1_diabetes[0],4),round(poly_result_f1_diabetes[0],4),round(rbf_result_f1_diabetes[0],4),round(ann_result_f1_diabetes[0],4),round(rf_result_f1_diabetes[0],4)],
                       [round(linear_result_f1_diabetes[1],4),round(poly_result_f1_diabetes[1],4),round(rbf_result_f1_diabetes[1],4),round(ann_result_f1_diabetes[1],4),round(rf_result_f1_diabetes[1],4)],
                       [round(linear_result_f1_diabetes[2],4),round(poly_result_f1_diabetes[2],4),round(rbf_result_f1_diabetes[2],4),round(ann_result_f1_diabetes[2],4),round(rf_result_f1_diabetes[2],4)],
                       [round(linear_result_f1_diabetes[3],4),round(poly_result_f1_diabetes[3],4),round(rbf_result_f1_diabetes[3],4),round(ann_result_f1_diabetes[3],4),round(rf_result_f1_diabetes[3],4)],
                       [round(linear_result_f1_diabetes[4],4),round(poly_result_f1_diabetes[4],4),round(rbf_result_f1_diabetes[4],4),round(ann_result_f1_diabetes[4],4),round(rf_result_f1_diabetes[4],4)],
                       [round(linear_result_f1_diabetes[5],4),round(poly_result_f1_diabetes[5],4),round(rbf_result_f1_diabetes[5],4),round(ann_result_f1_diabetes[5],4),round(rf_result_f1_diabetes[5],4)],
                       [round(linear_result_f1_diabetes[6],4),round(poly_result_f1_diabetes[6],4),round(rbf_result_f1_diabetes[6],4),round(ann_result_f1_diabetes[6],4),round(rf_result_f1_diabetes[6],4)],
                       [round(linear_result_f1_diabetes[7],4),round(poly_result_f1_diabetes[7],4),round(rbf_result_f1_diabetes[7],4),round(ann_result_f1_diabetes[7],4),round(rf_result_f1_diabetes[7],4)],
                       [round(linear_result_f1_diabetes[8],4),round(poly_result_f1_diabetes[8],4),round(rbf_result_f1_diabetes[8],4),round(ann_result_f1_diabetes[8],4),round(rf_result_f1_diabetes[8],4)],
                       [round(linear_result_f1_diabetes[9],4),round(poly_result_f1_diabetes[9],4),round(rbf_result_f1_diabetes[9],4),round(ann_result_f1_diabetes[9],4),round(rf_result_f1_diabetes[9],4)],
                       [round(linear_result_f1_diabetes[10],4),round(poly_result_f1_diabetes[10],4),round(rbf_result_f1_diabetes[10],4),round(ann_result_f1_diabetes[10],4),round(rf_result_f1_diabetes[10],4)]
                       ], # 2nd column
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['ELA ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_ela_result_diabetes[0],4),round(poly_ela_result_diabetes[0],4),round(rbf_ela_result_diabetes[0],4),round(ann_ela_result_diabetes[0],4),round(rf_ela_result_diabetes[0],4)],
                       [round(linear_ela_result_diabetes[1],4),round(poly_ela_result_diabetes[1],4),round(rbf_ela_result_diabetes[1],4),round(ann_ela_result_diabetes[1],4),round(rf_ela_result_diabetes[1],4)],
                       [round(linear_ela_result_diabetes[2],4),round(poly_ela_result_diabetes[2],4),round(rbf_ela_result_diabetes[2],4),round(ann_ela_result_diabetes[2],4),round(rf_ela_result_diabetes[2],4)],
                       [round(linear_ela_result_diabetes[3],4),round(poly_ela_result_diabetes[3],4),round(rbf_ela_result_diabetes[3],4),round(ann_ela_result_diabetes[3],4),round(rf_ela_result_diabetes[3],4)],
                       [round(linear_ela_result_diabetes[4],4),round(poly_ela_result_diabetes[4],4),round(rbf_ela_result_diabetes[4],4),round(ann_ela_result_diabetes[4],4),round(rf_ela_result_diabetes[4],4)],
                       [round(linear_ela_result_diabetes[5],4),round(poly_ela_result_diabetes[5],4),round(rbf_ela_result_diabetes[5],4),round(ann_ela_result_diabetes[5],4),round(rf_ela_result_diabetes[5],4)],
                       [round(linear_ela_result_diabetes[6],4),round(poly_ela_result_diabetes[6],4),round(rbf_ela_result_diabetes[6],4),round(ann_ela_result_diabetes[6],4),round(rf_ela_result_diabetes[6],4)],
                       [round(linear_ela_result_diabetes[7],4),round(poly_ela_result_diabetes[7],4),round(rbf_ela_result_diabetes[7],4),round(ann_ela_result_diabetes[7],4),round(rf_ela_result_diabetes[7],4)],
                       [round(linear_ela_result_diabetes[8],4),round(poly_ela_result_diabetes[8],4),round(rbf_ela_result_diabetes[8],4),round(ann_ela_result_diabetes[8],4),round(rf_ela_result_diabetes[8],4)],
                       [round(linear_ela_result_diabetes[9],4),round(poly_ela_result_diabetes[9],4),round(rbf_ela_result_diabetes[9],4),round(ann_ela_result_diabetes[9],4),round(rf_ela_result_diabetes[9],4)],
                       [round(linear_ela_result_diabetes[10],4),round(poly_ela_result_diabetes[10],4),round(rbf_ela_result_diabetes[10],4),round(ann_ela_result_diabetes[10],4),round(rf_ela_result_diabetes[10],4)]
                       ], 
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Time (s)',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(time_linear_sum_diabetes[0],4),round(time_poly_sum_diabetes[0],4),round(time_rbf_sum_diabetes[0],4),round(time_ann_sum_diabetes[0],4),round(time_rf_sum_diabetes[0],4)],
                       [round(time_linear_sum_diabetes[1],4),round(time_poly_sum_diabetes[1],4),round(time_rbf_sum_diabetes[1],4),round(time_ann_sum_diabetes[1],4),round(time_rf_sum_diabetes[1],4)],
                       [round(time_linear_sum_diabetes[2],4),round(time_poly_sum_diabetes[2],4),round(time_rbf_sum_diabetes[2],4),round(time_ann_sum_diabetes[2],4),round(time_rf_sum_diabetes[2],4)],
                       [round(time_linear_sum_diabetes[3],4),round(time_poly_sum_diabetes[3],4),round(time_rbf_sum_diabetes[3],4),round(time_ann_sum_diabetes[3],4),round(time_rf_sum_diabetes[3],4)],
                       [round(time_linear_sum_diabetes[4],4),round(time_poly_sum_diabetes[4],4),round(time_rbf_sum_diabetes[4],4),round(time_ann_sum_diabetes[4],4),round(time_rf_sum_diabetes[4],4)],
                       [round(time_linear_sum_diabetes[5],4),round(time_poly_sum_diabetes[5],4),round(time_rbf_sum_diabetes[5],4),round(time_ann_sum_diabetes[5],4),round(time_rf_sum_diabetes[5],4)],
                       [round(time_linear_sum_diabetes[6],4),round(time_poly_sum_diabetes[6],4),round(time_rbf_sum_diabetes[6],4),round(time_ann_sum_diabetes[6],4),round(time_rf_sum_diabetes[6],4)],
                       [round(time_linear_sum_diabetes[7],4),round(time_poly_sum_diabetes[7],4),round(time_rbf_sum_diabetes[7],4),round(time_ann_sum_diabetes[7],4),round(time_rf_sum_diabetes[7],4)],
                       [round(time_linear_sum_diabetes[8],4),round(time_poly_sum_diabetes[8],4),round(time_rbf_sum_diabetes[8],4),round(time_ann_sum_diabetes[8],4),round(time_rf_sum_diabetes[8],4)],
                       [round(time_linear_sum_diabetes[9],4),round(time_poly_sum_diabetes[9],4),round(time_rbf_sum_diabetes[9],4),round(time_ann_sum_diabetes[9],4),round(time_rf_sum_diabetes[9],4)],
                       [round(time_linear_sum_diabetes[10],4),round(time_poly_sum_diabetes[10],4),round(time_rbf_sum_diabetes[10],4),round(time_ann_sum_diabetes[10],4),round(time_rf_sum_diabetes[10],4)]
                       ], 
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Classifier','Total Time (s)'],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(sum(time_linear_sum_diabetes),4),round(sum(time_poly_sum_diabetes),4),round(sum(time_rbf_sum_diabetes),4),round(sum(time_ann_sum_diabetes),4),round(sum(time_rf_sum_diabetes),4)],
                       ], 
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

"""# Spam"""

#importing the libraries
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns 
import pandas as pd
import math
import time
from imblearn.over_sampling import SMOTE
from statistics import mean
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.svm import SVC
from sklearn import svm
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

#Loading datasets
df=pd.read_csv('spambase.csv')

df

df = df.rename(columns = {'1':'c1','2':'c2','3':'c3','4':'c4','5':'c5','6':'c6','7':'c7','8':'c8','9':'c9','10':'c10',
        '11':'c11','12':'c12','13':'c13','14':'c14','15':'c15','16':'c16','17':'c17','18':'c18','19':'c19','20':'c20',
        '21':'c21','22':'c22','23':'c23','24':'c24','25':'c25','26':'c26','27':'c27','28':'c28','29':'c29','30':'c30',
        '31':'c31','32':'c32','33':'c33','34':'c34','35':'c35','36':'c36','37':'c37','38':'c38','39':'c39','40':'c40',
        '41':'c41','42':'c42','43':'c43','44':'c44','45':'c45','46':'c46','47':'c47','48':'c48','49':'c49','50':'c50',
        '51':'c51','52':'c52','53':'c53','54':'c54','55':'c55','56':'c56','57':'c57','58':'c58'
                                   }, inplace = False)

# How does the proportion of the Target values look like?
df.c58.value_counts()

# X,y,etc should be the size which can be divided by n for n-fold cv. Some lows can be discarded. 
cv = 5
# s will be the length of the dataset <= length which can be divided by cv. 
s = math.floor(len(df)/cv)*cv
# d is the size of each partitioned dataset
d = int(s/cv)

X = df.iloc[:s,:-1].values
y = df.iloc[:s,-1].values
X_noise = df.iloc[:s,:-1].values.copy()

# 10 datasets which is going to be noised. 10%, 20% and so on. 
noise = []
n_range = range(0,10)
for n in n_range:
    noise.append(df.iloc[:s,:-1].values.copy())

df.shape

X.shape

# Make mean, std, max and min of every column
n_range = range(0, X.shape[1])
mean = []
std = []
max = []
min = []

for n in n_range: 
    mean.append(X_noise[:,n].mean())
    std.append(X_noise[:,n].std())
    max.append(X_noise[:,n].max())
    min.append(X_noise[:,n].min())

# New noise 

m_range = range(1,11)
for m in m_range:
    X_noise = noise[m-1]
    
    #noise_levels are going to be 0.1, 0.2,...1(10%,20%...)
    noise_level = 0.1 * m
    
    #How many entries(rows) in the dataset we want to add noise?
    noise_entries_amount = int(X.size * noise_level) 
    
    #Create an array with random int which represent the rows we are going to add noise on(no duplicate rows)
    r = np.random.choice(X.size, noise_entries_amount, replace=False)

    r_range = range(0,r.size)
    for n in r_range:
        entry = r[n]
        row = int(entry/X.shape[1])
        column = entry%X.shape[1]
            
        g_noise = np.random.normal(mean[column], std[column])
        # if the gaussian noise is greater than the max value of the column, we take the max value as noise. 
        if g_noise > max[column]:
            g_noise = max[column]
            X_noise[row][column] = X_noise[row][column] + g_noise
        # if the gaussian noise is smaller than the min value of the column, we take the min value as noise. 
        elif g_noise < 0:
            g_noise = min[column]
            X_noise[row][column] = X_noise[row][column] + g_noise

        else: 
            X_noise[row][column] = X_noise[row][column] + g_noise
        

# Partitioning

# p stands for partitioned
X_p = []
y_p = []
# Each [] will contain noised dataset 10%, 20%... which are divided in cv(e.g. 5)
noise_p = [[],[],[],[],[],[],[],[],[],[],]

n_range = range(0,10)
for n in n_range:
    for i in range(0, len(X), d):
            noise_p[n].append(noise[n][i:i + d])
for i in range(0, len(X), d):
            X_p.append(X[i:i + d])
            y_p.append(y[i:i + d])

# Cross Validation

linear_means_ac = []
poly_means_ac = []
rbf_means_ac = []
ann_means_ac = []
rf_means_ac = []

linear_means_f1 = []
poly_means_f1 = []
rbf_means_f1 = []
ann_means_f1 = []
rf_means_f1 = []

linear_means_noise_ac = []
poly_means_noise_ac = []
rbf_means_noise_ac = []
ann_means_noise_ac = []
rf_means_noise_ac = []

linear_means_noise_f1 = []
poly_means_noise_f1 = []
rbf_means_noise_f1 = []
ann_means_noise_f1 = []
rf_means_noise_f1 = []

time_linear_sum_spam = []
time_poly_sum_spam = []
time_rbf_sum_spam = []
time_ann_sum_spam = []
time_rf_sum_spam = []

# Cross Validation noise 0 
from statistics import mean
first = False
scores_linear_ac = []
scores_poly_ac = []
scores_rbf_ac = []
scores_ann_ac = []
scores_rf_ac = []

scores_linear_f1 = []
scores_poly_f1 = []
scores_rbf_f1 = []
scores_ann_f1 = []
scores_rf_f1 = []

time_linear_spam = []
time_poly_spam = []
time_rbf_spam = []
time_ann_spam = []
time_rf_spam = []

for i in range(cv):
    start = time.time()
    X_test = X_p[i]
    y_test = y_p[i]
    first = True
    for k in range(cv):
        if k != i:
            if first != True:
                X_train = np.append(X_train, X_p[k], axis=0)
                y_train = np.append(y_train, y_p[k], axis=0)
            else: 
                X_train = X_p[k]
                y_train = y_p[k]
                first = False

        
    # Now all test, train sets are obtained
    linear = svm.SVC(kernel='linear')
    poly = svm.SVC(kernel='poly')
    rbf = svm.SVC(kernel='rbf')
    ann = MLPClassifier(hidden_layer_sizes=(10,10,10), max_iter=1000)
    rf = RandomForestClassifier(n_estimators=200)
        
    # Our data is biased, we can fix this with SMOTE
    #oversample = SMOTE()
    #X_train, y_train = oversample.fit_resample(X_train, y_train)

    # Train the models
    sc = StandardScaler()
    X_train = sc.fit_transform(X_train)
    X_test = sc.transform(X_test)
    end = time.time()
    t = end-start
    
    linear_start = time.time()
    linear.fit(X_train, y_train)
    pred_linear = linear.predict(X_test)        
    score_linear_ac = accuracy_score(y_test, pred_linear)
    score_linear_f1 = f1_score(y_test, pred_linear)
    scores_linear_ac.append(score_linear_ac)
    scores_linear_f1.append(score_linear_f1)
    linear_end = time.time()
    time_linear_spam.append(t+(linear_end-linear_start))
    
    poly_start = time.time()
    poly.fit(X_train, y_train)
    pred_poly = poly.predict(X_test)        
    score_poly_ac = accuracy_score(y_test, pred_poly)
    score_poly_f1 = f1_score(y_test, pred_poly)
    scores_poly_ac.append(score_poly_ac)
    scores_poly_f1.append(score_poly_f1)
    poly_end = time.time()
    time_poly_spam.append(t+(poly_end-poly_start))
    
    rbf_start = time.time()
    rbf.fit(X_train, y_train)
    pred_rbf = rbf.predict(X_test)
    score_rbf_ac = accuracy_score(y_test, pred_rbf)
    scores_rbf_ac.append(score_rbf_ac)
    score_rbf_f1 = f1_score(y_test, pred_rbf)
    scores_rbf_f1.append(score_rbf_f1)
    rbf_end = time.time()
    time_rbf_spam.append(t+(rbf_end-rbf_start))

    ann_start = time.time()
    ann.fit(X_train, y_train)
    pred_ann = ann.predict(X_test)
    score_ann_ac = accuracy_score(y_test, pred_ann)
    scores_ann_ac.append(score_ann_ac)
    score_ann_f1 = f1_score(y_test, pred_ann)
    scores_ann_f1.append(score_ann_f1)
    ann_end = time.time()
    time_ann_spam.append(t+(ann_end-ann_start))

    rf_start = time.time()
    rf.fit(X_train, y_train)
    pred_rf = rf.predict(X_test)
    score_rf_ac = accuracy_score(y_test, pred_rf)
    scores_rf_ac.append(score_rf_ac)
    score_rf_f1 = f1_score(y_test, pred_rf)
    scores_rf_f1.append(score_rf_f1)
    rf_end = time.time()
    time_rf_spam.append(t+(rf_end-rf_start))

time_linear_sum_spam.append(sum(time_linear_spam))
time_poly_sum_spam.append(sum(time_poly_spam))
time_rbf_sum_spam.append(sum(time_rbf_spam))
time_ann_sum_spam.append(sum(time_ann_spam))
time_rf_sum_spam.append(sum(time_rf_spam))

    
print("Noise level 0")    
print("Linear accuracy mean is: ", mean(scores_linear_ac))
print("Linear f1 mean is: ", mean(scores_linear_f1))
print("")  
linear_means_ac.append(mean(scores_linear_ac))   
linear_means_f1.append(mean(scores_linear_f1))     

print("Noise level 0")    
print("Poly accuracy mean is: ", mean(scores_poly_ac))
print("Poly f1 mean is: ", mean(scores_poly_f1))
print("")  
poly_means_ac.append(mean(scores_poly_ac))   
poly_means_f1.append(mean(scores_poly_f1))     

print("Noise level 0")    
print("Rbf accuracy mean is: ", mean(scores_rbf_ac))
print("Rbf f1 mean is: ", mean(scores_rbf_f1))
print("")
rbf_means_ac.append(mean(scores_rbf_ac))
rbf_means_f1.append(mean(scores_rbf_f1))

print("Noise level 0")    
print("ANN accuracy mean is: ", mean(scores_ann_ac))
print("ANN f1 mean is: ", mean(scores_ann_f1))
print("")
ann_means_ac.append(mean(scores_ann_ac))
ann_means_f1.append(mean(scores_ann_f1))

print("Noise level 0")    
print("RF accuracy mean is: ", mean(scores_rf_ac))
print("RF f1 mean is: ", mean(scores_rf_f1))
print("")
rf_means_ac.append(mean(scores_rf_ac))
rf_means_f1.append(mean(scores_rf_f1))

print("Time linear: ", time_linear_sum_spam[0])
print("Time poly: ", time_poly_sum_spam[0])
print("Time rbf: ", time_rbf_sum_spam[0])
print("Time ann: ", time_ann_sum_spam[0])
print("Time rf: ", time_rf_sum_spam[0])


# Cross Validation Linear
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_linear_ac = []
    scores_linear_f1 = []
  
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
        
                    
        # Now all test, train sets are obtained
        linear = svm.SVC(kernel='linear')
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train)
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        linear.fit(X_train, y_train)
        pred_linear = linear.predict(X_test)        
        score_linear_ac = accuracy_score(y_test, pred_linear)
        score_linear_f1 = f1_score(y_test, pred_linear)

        scores_linear_ac.append(score_linear_ac)
        scores_linear_f1.append(score_linear_f1)
    end = time.time()
    t = end-start
    time_linear_sum_spam.append(t)

    print("Noise level: " + str((n+1)*10) + '%')    
    print("Linear accuracy mean is: ", mean(scores_linear_ac))
    print("Linear f1 mean is: ", mean(scores_linear_f1))
    print("Linear time: ", t)

    print("")  
    linear_means_noise_ac.append(mean(scores_linear_ac))
    linear_means_noise_f1.append(mean(scores_linear_f1))


# Cross Validation Poly
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_poly_ac = []
    scores_poly_f1 = []
 
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        poly = svm.SVC(kernel='poly')
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train)
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        poly.fit(X_train, y_train)
        pred_poly = poly.predict(X_test)        
        score_poly_ac = accuracy_score(y_test, pred_poly)
        score_poly_f1 = f1_score(y_test, pred_poly)

        scores_poly_ac.append(score_poly_ac)
        scores_poly_f1.append(score_poly_f1)
    end = time.time()
    t = end-start
    time_poly_sum_spam.append(t)


    print("Noise level: " + str((n+1)*10) + '%')    
    print("Poly accuracy mean is: ", mean(scores_poly_ac))
    print("Poly f1 mean is: ", mean(scores_poly_f1))
    print("Poly time: ", t)

    print("")  
    poly_means_noise_ac.append(mean(scores_poly_ac))
    poly_means_noise_f1.append(mean(scores_poly_f1))


# Cross Validation Rbf
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_rbf_ac = []
    scores_rbf_f1 = []
  
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        rbf = svm.SVC(kernel='rbf')
        
        # Train the models
        #Applying Standard scaling to get optimized result
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        rbf.fit(X_train, y_train)
        pred_rbf = rbf.predict(X_test)
       
        score_rbf_ac = accuracy_score(y_test, pred_rbf)
        score_rbf_f1 = f1_score(y_test, pred_rbf)

        scores_rbf_ac.append(score_rbf_ac)
        scores_rbf_f1.append(score_rbf_f1)
    end = time.time()
    t = end-start
    time_rbf_sum_spam.append(t)
   
    print("Noise level: " + str((n+1)*10) + '%')    
    print("Rbf accuracy mean is: ", mean(scores_rbf_ac))
    print("Rbf f1 mean is: ", mean(scores_rbf_f1))
    print("Rbf time: ", t)

    print("")  
    rbf_means_noise_ac.append(mean(scores_rbf_ac))
    rbf_means_noise_f1.append(mean(scores_rbf_f1))


# Cross Validation ANN
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_ann_ac = []
    scores_ann_f1 = []
    
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        ann = MLPClassifier(hidden_layer_sizes=(10,10,10), max_iter=1000)
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train.ravel())
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        ann.fit(X_train, y_train)
        pred_ann = ann.predict(X_test)
        
        score_ann_ac = accuracy_score(y_test, pred_ann)
        score_ann_f1 = f1_score(y_test, pred_ann)

        scores_ann_ac.append(score_ann_ac)
        scores_ann_f1.append(score_ann_f1)
    end = time.time()
    t = end-start
    time_ann_sum_spam.append(t)
    
    print("Noise level: " + str((n+1)*10) + '%')    
    print("ANN accuracy mean is: ", mean(scores_ann_ac))
    print("ANN f1 mean is: ", mean(scores_ann_f1))
    print("Ann time: ", t)

    print("")  
    ann_means_noise_ac.append(mean(scores_ann_ac))
    ann_means_noise_f1.append(mean(scores_ann_f1))


# Cross Validation RF
from statistics import mean
first = False

for n in range(len(noise_p)):
    start = time.time()
    scores_rf_ac = []
    scores_rf_f1 = []
    
    for i in range(cv):
        X_test = X_p[i]
        y_test = y_p[i]
        first = True
        for k in range(cv):
            if k != i:
                if first != True:
                    X_train = np.append(X_train, noise_p[n][k], axis=0)
                    y_train = np.append(y_train, y_p[k], axis=0)
                else: 
                    X_train = noise_p[n][k]
                    y_train = y_p[k]
                    first = False
                    
        # Now all test, train sets are obtained
        rf = RandomForestClassifier(n_estimators=200)
        
        # Our data is biased, we can fix this with SMOTE
        #oversample = SMOTE()
        #X_train, y_train = oversample.fit_resample(X_train, y_train.ravel())
        
        # Train the models
        sc = StandardScaler()
        X_train = sc.fit_transform(X_train)
        X_test = sc.transform(X_test)
        rf.fit(X_train, y_train)
        pred_rf = rf.predict(X_test)
        
        score_rf_ac = accuracy_score(y_test, pred_rf)
        score_rf_f1 = f1_score(y_test, pred_rf)

        scores_rf_ac.append(score_rf_ac)
        scores_rf_f1.append(score_rf_f1)
    end = time.time()
    t = end-start
    time_rf_sum_spam.append(t)
    
    print("Noise level: " + str((n+1)*10) + '%')    
    print("RF accuracy mean is: ", mean(scores_rf_ac))
    print("RF f1 mean is: ", mean(scores_rf_f1))
    print("Rf time: ", t)

    print("")  
    rf_means_noise_ac.append(mean(scores_rf_ac))
    rf_means_noise_f1.append(mean(scores_rf_f1))


# Make arrays with all the results [noise0, noise10%, noise20%..]
linear_result_ac_spam = linear_means_ac.copy()
poly_result_ac_spam = poly_means_ac.copy()
rbf_result_ac_spam = rbf_means_ac.copy()
ann_result_ac_spam = ann_means_ac.copy()
rf_result_ac_spam = rf_means_ac.copy()

linear_result_f1_spam = linear_means_f1.copy()
poly_result_f1_spam = poly_means_f1.copy()
rbf_result_f1_spam = rbf_means_f1.copy()
ann_result_f1_spam = ann_means_f1.copy()
rf_result_f1_spam = rf_means_f1.copy()

for i in range (10):
    linear_result_ac_spam.append(linear_means_noise_ac[i]) 
    poly_result_ac_spam.append(poly_means_noise_ac[i]) 
    rbf_result_ac_spam.append(rbf_means_noise_ac[i]) 
    ann_result_ac_spam.append(ann_means_noise_ac[i]) 
    rf_result_ac_spam.append(rf_means_noise_ac[i]) 
    
    linear_result_f1_spam.append(linear_means_noise_f1[i]) 
    poly_result_f1_spam.append(poly_means_noise_f1[i]) 
    rbf_result_f1_spam.append(rbf_means_noise_f1[i]) 
    ann_result_f1_spam.append(ann_means_noise_f1[i]) 
    rf_result_f1_spam.append(rf_means_noise_f1[i])
    
# Make ELA
linear_ela_result_spam = []
poly_ela_result_spam = []
rbf_ela_result_spam = []
ann_ela_result_spam = []
rf_ela_result_spam = []

linear_ela_result_spam.append((100-100*linear_means_ac[0])/(100*linear_means_ac[0]))
poly_ela_result_spam.append((100-100*poly_means_ac[0])/(100*poly_means_ac[0]))
rbf_ela_result_spam.append((100-100*rbf_means_ac[0])/(100*rbf_means_ac[0]))
ann_ela_result_spam.append((100-100*ann_means_ac[0])/(100*ann_means_ac[0]))
rf_ela_result_spam.append((100-100*rf_means_ac[0])/(100*rf_means_ac[0]))


for i in range (10):
    linear_ela = (100-100*linear_means_noise_ac[i])/(100*linear_means_ac[0])
    poly_ela = (100-100*poly_means_noise_ac[i])/(100*poly_means_ac[0])
    rbf_ela = (100-100*rbf_means_noise_ac[i])/(100*rbf_means_ac[0])
    ann_ela = (100-100*ann_means_noise_ac[i])/(100*ann_means_ac[0])
    rf_ela = (100-100*rf_means_noise_ac[i])/(100*rf_means_ac[0])
    
    linear_ela_result_spam.append(linear_ela)
    poly_ela_result_spam.append(poly_ela)
    rbf_ela_result_spam.append(rbf_ela)
    ann_ela_result_spam.append(ann_ela)
    rf_ela_result_spam.append(rf_ela)

# Commented out IPython magic to ensure Python compatibility.
# Accuracy Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_result_ac_spam, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, poly_result_ac_spam, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, rbf_result_ac_spam, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, ann_result_ac_spam, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.plot(k_range, rf_result_ac_spam, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated Accuracy')

plt.legend()

# Commented out IPython magic to ensure Python compatibility.
# F1-score Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_result_f1_spam, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, poly_result_f1_spam, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, rbf_result_f1_spam, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, ann_result_f1_spam, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.plot(k_range, rf_result_f1_spam, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated F-score')

plt.legend()

# Commented out IPython magic to ensure Python compatibility.
# ELA Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_ela_result_spam, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, poly_ela_result_spam, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, rbf_ela_result_spam, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, ann_ela_result_spam, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.plot(k_range, rf_ela_result_spam, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validated ELA')

plt.legend()

# Commented out IPython magic to ensure Python compatibility.
# Time Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, time_linear_sum_spam, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_poly_sum_spam, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_rbf_sum_spam, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_ann_sum_spam, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.plot(k_range, time_rf_sum_spam, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Time (s)')

plt.legend()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Accuracy  ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_result_ac_spam[0],4),round(poly_result_ac_spam[0],4),round(rbf_result_ac_spam[0],4),round(ann_result_ac_spam[0],4),round(rf_result_ac_spam[0],4)],
                       [round(linear_result_ac_spam[1],4),round(poly_result_ac_spam[1],4),round(rbf_result_ac_spam[1],4),round(ann_result_ac_spam[1],4),round(rf_result_ac_spam[1],4)],
                       [round(linear_result_ac_spam[2],4),round(poly_result_ac_spam[2],4),round(rbf_result_ac_spam[2],4),round(ann_result_ac_spam[2],4),round(rf_result_ac_spam[2],4)],
                       [round(linear_result_ac_spam[3],4),round(poly_result_ac_spam[3],4),round(rbf_result_ac_spam[3],4),round(ann_result_ac_spam[3],4),round(rf_result_ac_spam[3],4)],
                       [round(linear_result_ac_spam[4],4),round(poly_result_ac_spam[4],4),round(rbf_result_ac_spam[4],4),round(ann_result_ac_spam[4],4),round(rf_result_ac_spam[4],4)],
                       [round(linear_result_ac_spam[5],4),round(poly_result_ac_spam[5],4),round(rbf_result_ac_spam[5],4),round(ann_result_ac_spam[5],4),round(rf_result_ac_spam[5],4)],
                       [round(linear_result_ac_spam[6],4),round(poly_result_ac_spam[6],4),round(rbf_result_ac_spam[6],4),round(ann_result_ac_spam[6],4),round(rf_result_ac_spam[6],4)],
                       [round(linear_result_ac_spam[7],4),round(poly_result_ac_spam[7],4),round(rbf_result_ac_spam[7],4),round(ann_result_ac_spam[7],4),round(rf_result_ac_spam[7],4)],
                       [round(linear_result_ac_spam[8],4),round(poly_result_ac_spam[8],4),round(rbf_result_ac_spam[8],4),round(ann_result_ac_spam[8],4),round(rf_result_ac_spam[8],4)],
                       [round(linear_result_ac_spam[9],4),round(poly_result_ac_spam[9],4),round(rbf_result_ac_spam[9],4),round(ann_result_ac_spam[9],4),round(rf_result_ac_spam[9],4)],
                       [round(linear_result_ac_spam[10],4),round(poly_result_ac_spam[10],4),round(rbf_result_ac_spam[10],4),round(ann_result_ac_spam[10],4),round(rf_result_ac_spam[10],4)]
                       ], # 2nd column
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['F-score ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_result_f1_spam[0],4),round(poly_result_f1_spam[0],4),round(rbf_result_f1_spam[0],4),round(ann_result_f1_spam[0],4),round(rf_result_f1_spam[0],4)],
                       [round(linear_result_f1_spam[1],4),round(poly_result_f1_spam[1],4),round(rbf_result_f1_spam[1],4),round(ann_result_f1_spam[1],4),round(rf_result_f1_spam[1],4)],
                       [round(linear_result_f1_spam[2],4),round(poly_result_f1_spam[2],4),round(rbf_result_f1_spam[2],4),round(ann_result_f1_spam[2],4),round(rf_result_f1_spam[2],4)],
                       [round(linear_result_f1_spam[3],4),round(poly_result_f1_spam[3],4),round(rbf_result_f1_spam[3],4),round(ann_result_f1_spam[3],4),round(rf_result_f1_spam[3],4)],
                       [round(linear_result_f1_spam[4],4),round(poly_result_f1_spam[4],4),round(rbf_result_f1_spam[4],4),round(ann_result_f1_spam[4],4),round(rf_result_f1_spam[4],4)],
                       [round(linear_result_f1_spam[5],4),round(poly_result_f1_spam[5],4),round(rbf_result_f1_spam[5],4),round(ann_result_f1_spam[5],4),round(rf_result_f1_spam[5],4)],
                       [round(linear_result_f1_spam[6],4),round(poly_result_f1_spam[6],4),round(rbf_result_f1_spam[6],4),round(ann_result_f1_spam[6],4),round(rf_result_f1_spam[6],4)],
                       [round(linear_result_f1_spam[7],4),round(poly_result_f1_spam[7],4),round(rbf_result_f1_spam[7],4),round(ann_result_f1_spam[7],4),round(rf_result_f1_spam[7],4)],
                       [round(linear_result_f1_spam[8],4),round(poly_result_f1_spam[8],4),round(rbf_result_f1_spam[8],4),round(ann_result_f1_spam[8],4),round(rf_result_f1_spam[8],4)],
                       [round(linear_result_f1_spam[9],4),round(poly_result_f1_spam[9],4),round(rbf_result_f1_spam[9],4),round(ann_result_f1_spam[9],4),round(rf_result_f1_spam[9],4)],
                       [round(linear_result_f1_spam[10],4),round(poly_result_f1_spam[10],4),round(rbf_result_f1_spam[10],4),round(ann_result_f1_spam[10],4),round(rf_result_f1_spam[10],4)]
                       ], # 2nd column
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['ELA ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_ela_result_spam[0],4),round(poly_ela_result_spam[0],4),round(rbf_ela_result_spam[0],4),round(ann_ela_result_spam[0],4),round(rf_ela_result_spam[0],4)],
                       [round(linear_ela_result_spam[1],4),round(poly_ela_result_spam[1],4),round(rbf_ela_result_spam[1],4),round(ann_ela_result_spam[1],4),round(rf_ela_result_spam[1],4)],
                       [round(linear_ela_result_spam[2],4),round(poly_ela_result_spam[2],4),round(rbf_ela_result_spam[2],4),round(ann_ela_result_spam[2],4),round(rf_ela_result_spam[2],4)],
                       [round(linear_ela_result_spam[3],4),round(poly_ela_result_spam[3],4),round(rbf_ela_result_spam[3],4),round(ann_ela_result_spam[3],4),round(rf_ela_result_spam[3],4)],
                       [round(linear_ela_result_spam[4],4),round(poly_ela_result_spam[4],4),round(rbf_ela_result_spam[4],4),round(ann_ela_result_spam[4],4),round(rf_ela_result_spam[4],4)],
                       [round(linear_ela_result_spam[5],4),round(poly_ela_result_spam[5],4),round(rbf_ela_result_spam[5],4),round(ann_ela_result_spam[5],4),round(rf_ela_result_spam[5],4)],
                       [round(linear_ela_result_spam[6],4),round(poly_ela_result_spam[6],4),round(rbf_ela_result_spam[6],4),round(ann_ela_result_spam[6],4),round(rf_ela_result_spam[6],4)],
                       [round(linear_ela_result_spam[7],4),round(poly_ela_result_spam[7],4),round(rbf_ela_result_spam[7],4),round(ann_ela_result_spam[7],4),round(rf_ela_result_spam[7],4)],
                       [round(linear_ela_result_spam[8],4),round(poly_ela_result_spam[8],4),round(rbf_ela_result_spam[8],4),round(ann_ela_result_spam[8],4),round(rf_ela_result_spam[8],4)],
                       [round(linear_ela_result_spam[9],4),round(poly_ela_result_spam[9],4),round(rbf_ela_result_spam[9],4),round(ann_ela_result_spam[9],4),round(rf_ela_result_spam[9],4)],
                       [round(linear_ela_result_spam[10],4),round(poly_ela_result_spam[10],4),round(rbf_ela_result_spam[10],4),round(ann_ela_result_spam[10],4),round(rf_ela_result_spam[10],4)]
                       ], 
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Time (s)',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(time_linear_sum_spam[0],4),round(time_poly_sum_spam[0],4),round(time_rbf_sum_spam[0],4),round(time_ann_sum_spam[0],4),round(time_rf_sum_spam[0],4)],
                       [round(time_linear_sum_spam[1],4),round(time_poly_sum_spam[1],4),round(time_rbf_sum_spam[1],4),round(time_ann_sum_spam[1],4),round(time_rf_sum_spam[1],4)],
                       [round(time_linear_sum_spam[2],4),round(time_poly_sum_spam[2],4),round(time_rbf_sum_spam[2],4),round(time_ann_sum_spam[2],4),round(time_rf_sum_spam[2],4)],
                       [round(time_linear_sum_spam[3],4),round(time_poly_sum_spam[3],4),round(time_rbf_sum_spam[3],4),round(time_ann_sum_spam[3],4),round(time_rf_sum_spam[3],4)],
                       [round(time_linear_sum_spam[4],4),round(time_poly_sum_spam[4],4),round(time_rbf_sum_spam[4],4),round(time_ann_sum_spam[4],4),round(time_rf_sum_spam[4],4)],
                       [round(time_linear_sum_spam[5],4),round(time_poly_sum_spam[5],4),round(time_rbf_sum_spam[5],4),round(time_ann_sum_spam[5],4),round(time_rf_sum_spam[5],4)],
                       [round(time_linear_sum_spam[6],4),round(time_poly_sum_spam[6],4),round(time_rbf_sum_spam[6],4),round(time_ann_sum_spam[6],4),round(time_rf_sum_spam[6],4)],
                       [round(time_linear_sum_spam[7],4),round(time_poly_sum_spam[7],4),round(time_rbf_sum_spam[7],4),round(time_ann_sum_spam[7],4),round(time_rf_sum_spam[7],4)],
                       [round(time_linear_sum_spam[8],4),round(time_poly_sum_spam[8],4),round(time_rbf_sum_spam[8],4),round(time_ann_sum_spam[8],4),round(time_rf_sum_spam[8],4)],
                       [round(time_linear_sum_spam[9],4),round(time_poly_sum_spam[9],4),round(time_rbf_sum_spam[9],4),round(time_ann_sum_spam[9],4),round(time_rf_sum_spam[9],4)],
                       [round(time_linear_sum_spam[10],4),round(time_poly_sum_spam[10],4),round(time_rbf_sum_spam[10],4),round(time_ann_sum_spam[10],4),round(time_rf_sum_spam[10],4)]
                       ], 
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Classifier','Total Time (s)'],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(sum(time_linear_sum_spam),4),round(sum(time_poly_sum_spam),4),round(sum(time_rbf_sum_spam),4),round(sum(time_ann_sum_spam),4),round(sum(time_rf_sum_spam),4)],
                       ], 
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

"""# Average"""

linear_ac_average = []
poly_ac_average = []
rbf_ac_average = []
ann_ac_average = []
rf_ac_average = []

linear_f1_average = []
poly_f1_average = []
rbf_f1_average = []
ann_f1_average = []
rf_f1_average = []

linear_ela_average = []
poly_ela_average = []
rbf_ela_average = []
ann_ela_average = []
rf_ela_average = []

linear_time_average = []
poly_time_average = []
rbf_time_average = []
ann_time_average = []
rf_time_average = []

for i in range(11):
    linear_ac_average.append((linear_result_ac_bc[i]+linear_result_ac_banknote[i]
                             +linear_result_ac_diabetes[i]+linear_result_ac_spam[i])/4)
    poly_ac_average.append((poly_result_ac_bc[i]+poly_result_ac_banknote[i]
                             +poly_result_ac_diabetes[i]+poly_result_ac_spam[i])/4)
    rbf_ac_average.append((rbf_result_ac_bc[i]+rbf_result_ac_banknote[i]
                             +rbf_result_ac_diabetes[i]+rbf_result_ac_spam[i])/4)
    ann_ac_average.append((ann_result_ac_bc[i]+ann_result_ac_banknote[i]
                             +ann_result_ac_diabetes[i]+ann_result_ac_spam[i])/4)
    rf_ac_average.append((rf_result_ac_bc[i]+rf_result_ac_banknote[i]
                             +rf_result_ac_diabetes[i]+rf_result_ac_spam[i])/4)
    
    linear_f1_average.append((linear_result_f1_bc[i]+linear_result_f1_banknote[i]
                             +linear_result_f1_diabetes[i]+linear_result_f1_spam[i])/4)
    poly_f1_average.append((poly_result_f1_bc[i]+poly_result_f1_banknote[i]
                             +poly_result_f1_diabetes[i]+poly_result_f1_spam[i])/4)
    rbf_f1_average.append((rbf_result_f1_bc[i]+rbf_result_f1_banknote[i]
                             +rbf_result_f1_diabetes[i]+rbf_result_f1_spam[i])/4)
    ann_f1_average.append((ann_result_f1_bc[i]+ann_result_f1_banknote[i]
                             +ann_result_f1_diabetes[i]+ann_result_f1_spam[i])/4)
    rf_f1_average.append((rf_result_f1_bc[i]+rf_result_f1_banknote[i]
                             +rf_result_f1_diabetes[i]+rf_result_f1_spam[i])/4)
    
    linear_ela_average.append((linear_ela_result_bc[i]+linear_ela_result_banknote[i]
                             +linear_ela_result_diabetes[i]+linear_ela_result_spam[i])/4)
    poly_ela_average.append((poly_ela_result_bc[i]+poly_ela_result_banknote[i]
                             +poly_ela_result_diabetes[i]+poly_ela_result_spam[i])/4)
    rbf_ela_average.append((rbf_ela_result_bc[i]+rbf_ela_result_banknote[i]
                             +rbf_ela_result_diabetes[i]+rbf_ela_result_spam[i])/4)
    ann_ela_average.append((ann_ela_result_bc[i]+ann_ela_result_banknote[i]
                             +ann_ela_result_diabetes[i]+ann_ela_result_spam[i])/4)
    rf_ela_average.append((rf_ela_result_bc[i]+rf_ela_result_banknote[i]
                             +rf_ela_result_diabetes[i]+rf_ela_result_spam[i])/4)
    
    linear_time_average.append((time_linear_sum_bc[i]+time_linear_sum_banknote[i]
                             +time_linear_sum_diabetes[i]+time_linear_sum_spam[i])/4)
    poly_time_average.append((time_poly_sum_bc[i]+time_poly_sum_banknote[i]
                             +time_poly_sum_diabetes[i]+time_poly_sum_spam[i])/4)
    rbf_time_average.append((time_rbf_sum_bc[i]+time_rbf_sum_banknote[i]
                             +time_rbf_sum_diabetes[i]+time_rbf_sum_spam[i])/4)
    ann_time_average.append((time_ann_sum_bc[i]+time_ann_sum_banknote[i]
                             +time_ann_sum_diabetes[i]+time_ann_sum_spam[i])/4)
    rf_time_average.append((time_rf_sum_bc[i]+time_rf_sum_banknote[i]
                             +time_rf_sum_diabetes[i]+time_rf_sum_spam[i])/4)

# Commented out IPython magic to ensure Python compatibility.
# Average accuracy Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_ac_average, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average Accuracy')

plt.plot(k_range, poly_ac_average, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Cross-Validationed Accuracy')

plt.plot(k_range, rbf_ac_average, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average Accuracy')

plt.plot(k_range, ann_ac_average, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average Accuracy')

plt.plot(k_range, rf_ac_average, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average Accuracy')

plt.legend()

# Commented out IPython magic to ensure Python compatibility.
# Average f1-score Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_f1_average, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average F-score')

plt.plot(k_range, poly_f1_average, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average F-score')

plt.plot(k_range, rbf_f1_average, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average F-score')

plt.plot(k_range, ann_f1_average, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average F-score')

plt.plot(k_range, rf_f1_average, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average F-score')

plt.legend()

# Commented out IPython magic to ensure Python compatibility.
# Average ela Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_ela_average, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average ELA')

plt.plot(k_range, poly_ela_average, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average ELA')

plt.plot(k_range, rbf_ela_average, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average ELA')

plt.plot(k_range, ann_ela_average, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average ELA')

plt.plot(k_range, rf_ela_average, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average ELA')

plt.legend()

# Commented out IPython magic to ensure Python compatibility.
# Average time Graph 
# %matplotlib inline

k_range = range(0,110,10)
plt.plot(k_range, linear_time_average, label='L-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average Time (s)')

plt.plot(k_range, poly_time_average, label='P-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average Time (s)')

plt.plot(k_range, rbf_time_average, label='RBF-SVC')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average Time (s)')

plt.plot(k_range, ann_time_average, label='ANN')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average Time (s)')

plt.plot(k_range, rf_time_average, label='RF')
plt.xlabel('Noise Level (%)')
plt.ylabel('Average Time (s)')

plt.legend()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Average Accuracy  ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_ac_average[0],4),round(poly_ac_average[0],4),round(rbf_ac_average[0],4),round(ann_ac_average[0],4),round(rf_ac_average[0],4)],
                       [round(linear_ac_average[1],4),round(poly_ac_average[1],4),round(rbf_ac_average[1],4),round(ann_ac_average[1],4),round(rf_ac_average[1],4)],
                       [round(linear_ac_average[2],4),round(poly_ac_average[2],4),round(rbf_ac_average[2],4),round(ann_ac_average[2],4),round(rf_ac_average[2],4)],
                       [round(linear_ac_average[3],4),round(poly_ac_average[3],4),round(rbf_ac_average[3],4),round(ann_ac_average[3],4),round(rf_ac_average[3],4)],
                       [round(linear_ac_average[4],4),round(poly_ac_average[4],4),round(rbf_ac_average[4],4),round(ann_ac_average[4],4),round(rf_ac_average[4],4)],
                       [round(linear_ac_average[5],4),round(poly_ac_average[5],4),round(rbf_ac_average[5],4),round(ann_ac_average[5],4),round(rf_ac_average[5],4)],
                       [round(linear_ac_average[6],4),round(poly_ac_average[6],4),round(rbf_ac_average[6],4),round(ann_ac_average[6],4),round(rf_ac_average[6],4)],
                       [round(linear_ac_average[7],4),round(poly_ac_average[7],4),round(rbf_ac_average[7],4),round(ann_ac_average[7],4),round(rf_ac_average[7],4)],
                       [round(linear_ac_average[8],4),round(poly_ac_average[8],4),round(rbf_ac_average[8],4),round(ann_ac_average[8],4),round(rf_ac_average[8],4)],
                       [round(linear_ac_average[9],4),round(poly_ac_average[9],4),round(rbf_ac_average[9],4),round(ann_ac_average[9],4),round(rf_ac_average[9],4)],
                       [round(linear_ac_average[10],4),round(poly_ac_average[10],4),round(rbf_ac_average[10],4),round(ann_ac_average[10],4),round(rf_ac_average[10],4)]
                       ], # 2nd column
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Average F-score  ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_f1_average[0],4),round(poly_f1_average[0],4),round(rbf_f1_average[0],4),round(ann_f1_average[0],4),round(rf_f1_average[0],4)],
                       [round(linear_f1_average[1],4),round(poly_f1_average[1],4),round(rbf_f1_average[1],4),round(ann_f1_average[1],4),round(rf_f1_average[1],4)],
                       [round(linear_f1_average[2],4),round(poly_f1_average[2],4),round(rbf_f1_average[2],4),round(ann_f1_average[2],4),round(rf_f1_average[2],4)],
                       [round(linear_f1_average[3],4),round(poly_f1_average[3],4),round(rbf_f1_average[3],4),round(ann_f1_average[3],4),round(rf_f1_average[3],4)],
                       [round(linear_f1_average[4],4),round(poly_f1_average[4],4),round(rbf_f1_average[4],4),round(ann_f1_average[4],4),round(rf_f1_average[4],4)],
                       [round(linear_f1_average[5],4),round(poly_f1_average[5],4),round(rbf_f1_average[5],4),round(ann_f1_average[5],4),round(rf_f1_average[5],4)],
                       [round(linear_f1_average[6],4),round(poly_f1_average[6],4),round(rbf_f1_average[6],4),round(ann_f1_average[6],4),round(rf_f1_average[6],4)],
                       [round(linear_f1_average[7],4),round(poly_f1_average[7],4),round(rbf_f1_average[7],4),round(ann_f1_average[7],4),round(rf_f1_average[7],4)],
                       [round(linear_f1_average[8],4),round(poly_f1_average[8],4),round(rbf_f1_average[8],4),round(ann_f1_average[8],4),round(rf_f1_average[8],4)],
                       [round(linear_f1_average[9],4),round(poly_f1_average[9],4),round(rbf_f1_average[9],4),round(ann_f1_average[9],4),round(rf_f1_average[9],4)],
                       [round(linear_f1_average[10],4),round(poly_f1_average[10],4),round(rbf_f1_average[10],4),round(ann_f1_average[10],4),round(rf_f1_average[10],4)]
                       ], # 2nd column
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Average ELA  ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_ela_average[0],4),round(poly_ela_average[0],4),round(rbf_ela_average[0],4),round(ann_ela_average[0],4),round(rf_ela_average[0],4)],
                       [round(linear_ela_average[1],4),round(poly_ela_average[1],4),round(rbf_ela_average[1],4),round(ann_ela_average[1],4),round(rf_ela_average[1],4)],
                       [round(linear_ela_average[2],4),round(poly_ela_average[2],4),round(rbf_ela_average[2],4),round(ann_ela_average[2],4),round(rf_ela_average[2],4)],
                       [round(linear_ela_average[3],4),round(poly_ela_average[3],4),round(rbf_ela_average[3],4),round(ann_ela_average[3],4),round(rf_ela_average[3],4)],
                       [round(linear_ela_average[4],4),round(poly_ela_average[4],4),round(rbf_ela_average[4],4),round(ann_ela_average[4],4),round(rf_ela_average[4],4)],
                       [round(linear_ela_average[5],4),round(poly_ela_average[5],4),round(rbf_ela_average[5],4),round(ann_ela_average[5],4),round(rf_ela_average[5],4)],
                       [round(linear_ela_average[6],4),round(poly_ela_average[6],4),round(rbf_ela_average[6],4),round(ann_ela_average[6],4),round(rf_ela_average[6],4)],
                       [round(linear_ela_average[7],4),round(poly_ela_average[7],4),round(rbf_ela_average[7],4),round(ann_ela_average[7],4),round(rf_ela_average[7],4)],
                       [round(linear_ela_average[8],4),round(poly_ela_average[8],4),round(rbf_ela_average[8],4),round(ann_ela_average[8],4),round(rf_ela_average[8],4)],
                       [round(linear_ela_average[9],4),round(poly_ela_average[9],4),round(rbf_ela_average[9],4),round(ann_ela_average[9],4),round(rf_ela_average[9],4)],
                       [round(linear_ela_average[10],4),round(poly_ela_average[10],4),round(rbf_ela_average[10],4),round(ann_ela_average[10],4),round(rf_ela_average[10],4)]
                       ], # 2nd column
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Table(
    header=dict(values=['Average Time (s) ',' 0% ',' 10% ',' 20% ',' 30% ',' 40% ',' 50% ',' 60% ',' 70% ',' 80% ',' 90% ',' 100% '],
                line_color='darkslategray',
                fill_color='lightskyblue',
                align='left'),
    cells=dict(values=[['L-SVC', 'P-SVC', 'RBF-SVC', 'ANN', 'RF'], # 1st column
                       [round(linear_time_average[0],4),round(poly_time_average[0],4),round(rbf_time_average[0],4),round(ann_time_average[0],4),round(rf_time_average[0],4)],
                       [round(linear_time_average[1],4),round(poly_time_average[1],4),round(rbf_time_average[1],4),round(ann_time_average[1],4),round(rf_time_average[1],4)],
                       [round(linear_time_average[2],4),round(poly_time_average[2],4),round(rbf_time_average[2],4),round(ann_time_average[2],4),round(rf_time_average[2],4)],
                       [round(linear_time_average[3],4),round(poly_time_average[3],4),round(rbf_time_average[3],4),round(ann_time_average[3],4),round(rf_time_average[3],4)],
                       [round(linear_time_average[4],4),round(poly_time_average[4],4),round(rbf_time_average[4],4),round(ann_time_average[4],4),round(rf_time_average[4],4)],
                       [round(linear_time_average[5],4),round(poly_time_average[5],4),round(rbf_time_average[5],4),round(ann_time_average[5],4),round(rf_time_average[5],4)],
                       [round(linear_time_average[6],4),round(poly_time_average[6],4),round(rbf_time_average[6],4),round(ann_time_average[6],4),round(rf_time_average[6],4)],
                       [round(linear_time_average[7],4),round(poly_time_average[7],4),round(rbf_time_average[7],4),round(ann_time_average[7],4),round(rf_time_average[7],4)],
                       [round(linear_time_average[8],4),round(poly_time_average[8],4),round(rbf_time_average[8],4),round(ann_time_average[8],4),round(rf_time_average[8],4)],
                       [round(linear_time_average[9],4),round(poly_time_average[9],4),round(rbf_time_average[9],4),round(ann_time_average[9],4),round(rf_time_average[9],4)],
                       [round(linear_time_average[10],4),round(poly_time_average[10],4),round(rbf_time_average[10],4),round(ann_time_average[10],4),round(rf_time_average[10],4)]
                       ], # 2nd column
               line_color='darkslategray',
               fill_color='lightcyan',
               align='left'))
])

fig.show()